{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testiranje granica sustava kod obrade nizova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovoj bilježnici biti će ispitano:\n",
    "* koliko vremena je potrebno za obradu 1. epohe skupa podataka, sličnog mojem, primjenom sekvencijalnih modela\n",
    "* kako u to ukomponirati operacije maskiranja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija za generiranje sekvencijalnih podataka proizvoljne dimenzionalnosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_data_generator(num_samples, feature_dim=2048, min_len=200, max_len=450):\n",
    "    '''Vraća sekvencijalni skup podataka proizvoljne dimenzionalnosti vremenskog koraka,\n",
    "    sa različitim slučajno generiranim brojem vremenskih koraka pojedinih opažanja.\n",
    "    \n",
    "    Argumenti:\n",
    "    ----------\n",
    "    num_samples: int\n",
    "    Broj opažanja.\n",
    "    \n",
    "    feature_dim: int\n",
    "    Dimenzionalnost svakog vremenskog koraka.\n",
    "    \n",
    "    min_len: int\n",
    "    Minimalna broj vremenskih koraka pojedinog opažanja.\n",
    "    \n",
    "    max_len: int\n",
    "    Maksimalni broj vremenskih koraka pojedinog opažanja.\n",
    "    \n",
    "    Povratna vrijednost:\n",
    "    --------------------\n",
    "    X, y: tuple(list(np.array), list(np.array))\n",
    "    Skup podataka i oznaka definiranih karakteristika\n",
    "    '''\n",
    "    #Generiranje broja vremenskih koraka pojedinog opažanja\n",
    "    seq_lengths = np.random.randint(min_len, max_len + 1, size=num_samples)\n",
    "    #Generiranja skupa opažanja\n",
    "    X = [np.random.randint(0, 256, (seq_lengths[sample], feature_dim)).astype(\"int32\") for sample in range(num_samples)]\n",
    "    #Normalizacija opažanja\n",
    "    X = [(sample / 255.).astype(\"float32\") for sample in X]\n",
    "    #Generiranje oznaka\n",
    "    y = [np.random.randint(0, 10, size=seq_lengths[sample]).astype(\"int32\") for sample in range(num_samples)]\n",
    "    #Izvlačenje podatka o veličini generiranog skupa opažanja\n",
    "    data_size = np.sum([sample.nbytes / 1e6 for sample in X])\n",
    "    #Ispis informacije o težini skupa podataka u MB-ima\n",
    "    print(f\"Generiran skup podataka sa {num_samples} opažanja, veličine: {data_size:.2f} MB\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Funkcija za izvlačenje duljina nizova iz generiranih podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_lengths(data, only_min_max=False):\n",
    "    '''Ispisuje broj vremenskih koraka svakog opažanja \n",
    "    ili samo najmanji i najveći broj vremenskih korak u skupu podataka'''\n",
    "    \n",
    "    lengths = [len(sample) for sample in data]\n",
    "    if only_min_max:\n",
    "        min_max = np.min(lengths), np.max(lengths)\n",
    "        print(min_max)\n",
    "    else:\n",
    "        print(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija za generiranje Dataseta, sa nadopunjenim batchevima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(X, y, batch_size):\n",
    "    '''Vraća tf.data.Dataset na temelju ulaznih podataka i oznaka u np.array formatu, \n",
    "    sa dinamičkom nadopunom mini grupa'''\n",
    "    \n",
    "    #Ovdje je potrebno napraviti generator jer su opažanja različitih duljina, \n",
    "    #Kada se podatci podižu iz TFRecorda formata nije potrebno koristiti generator\n",
    "    ds = tf.data.Dataset.from_generator(lambda: iter(zip(X, y)), \n",
    "                                       output_types=(tf.float32, tf.int32))\n",
    "    \n",
    "    #Potrebno je dati oznaku nadopunjavanja i za X i y \n",
    "    #(.) je bitna zbog toga jer jer tip podatka FLOAT\n",
    "    #Oznaka nadopuna za y mora biti 0, (inače ne radi: nan kod izračuna funkcije gubitka)\n",
    "    #bez obzira da li u skup podataka postoji oznaka 0, (nema utjecaj jer će nadopune biti maskirane!)\n",
    "    ds = ds.padded_batch(batch_size, padded_shapes=([None, 2048], [None]), padding_values=(10., 0))\n",
    "    \n",
    "    return ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija za generiranje kompajliranog modela za obradu nizova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompiled_model(num_units=512, bidirect=False):\n",
    "    '''Definiranje testnih modela'''\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    mask = tf.keras.layers.Masking(mask_value=(10.), input_shape=(None, 2048))(ulaz)\n",
    "    if bidirect:\n",
    "        srednji = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(num_units, return_sequences=True))(mask)\n",
    "    else:\n",
    "        srednji = tf.keras.layers.LSTM(num_units, return_sequences=True)(mask)\n",
    "    izlaz = tf.keras.layers.Dense(10, activation=\"softmax\")(srednji)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testiranje funkcije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjera da li se maske propagiraju do zadnjeg sloja, preduvjet je da se dimenzionalnost vremenskog koraka ne mijenja!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sloj broj 0: <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A0D2B75F88>\n",
      "Dimenzije ulazne maske: None\n",
      "Dimenzije izlazne maske: None\n",
      "Sloj broj 1: <tensorflow.python.keras.layers.core.Masking object at 0x000001A0CE64D048>\n",
      "Dimenzije ulazne maske: None\n",
      "Dimenzije izlazne maske: Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n",
      "Sloj broj 2: <tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x000001A0D6E164C8>\n",
      "Dimenzije ulazne maske: Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n",
      "Dimenzije izlazne maske: Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n",
      "Sloj broj 3: <tensorflow.python.keras.layers.core.Dense object at 0x000001A0D6DEB348>\n",
      "Dimenzije ulazne maske: Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n",
      "Dimenzije izlazne maske: Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "test_model = uncompiled_model()\n",
    "for num, layer in enumerate(test_model.layers):\n",
    "    print(f\"Sloj broj {num}: {layer}\")\n",
    "    print(f\"Dimenzije ulazne maske: {layer.input_mask}\")\n",
    "    print(f\"Dimenzije izlazne maske: {layer.output_mask}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maska je propagirana do kraja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija koja vraća kompajlirani model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compiled_model(num_units=512, bidirect=False, loss = tf.keras.losses.SparseCategoricalCrossentropy()):\n",
    "    '''Vraća kompajlirani model sa proizvoljno definiranom funkcijom cilja'''\n",
    "    \n",
    "    model = uncompiled_model(num_units, bidirect)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "                 loss = loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testiranje izlaza iz modela sa različitim funkcijama gubitka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiranje pokusnog uzorka uz manualno nadopunjavanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generiran skup podataka sa 1 opažanja, veličine: 0.06 MB\n",
      "(7, 2048) (7,)\n"
     ]
    }
   ],
   "source": [
    "#Generiranje uzorka\n",
    "X, y = video_data_generator(1, min_len=5, max_len=10)\n",
    "print(X[0].shape, y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ukupni broj vremenskih koraka sa nadopunama\n",
    "padded_sample_len = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prethodnim testiranjima došao sam do zaključka da nadopuna opažanja može biti bilo koji broj, uz uvjet da je odgovarajućeg tipa (npr. float32). Također se pokazalo da nadopuna oznaka **ne može** biti bilo kakav broj npr. -10 ili 10 jer tada u slučaju korištenja `SparseCategoricalCrossentropy` gubitka nije moguće dobiti riješenje i povratna vrijednost je `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 2048) (1, 40)\n"
     ]
    }
   ],
   "source": [
    "#Kreiranje uzorka koji je nadopunjen sa mask_value=10.\n",
    "X_test = np.full((padded_sample_len, 2048) , fill_value=10.)\n",
    "#Dodavanje generiranog uzorka u nadopunu\n",
    "X_test[:X[0].shape[0]] = X[0]\n",
    "#Dodavanje batch dimenzije, preduvjet framework-a \n",
    "X_test = np.expand_dims(X_test, axis=0)\n",
    "\n",
    "#Sličana postupak za oznake uz mask_value=0\n",
    "y_test = np.full(padded_sample_len, fill_value=0)\n",
    "y_test[:y[0].shape[0]] = y[0] \n",
    "y_test = np.expand_dims(y_test, axis=0)\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatno je potrebno napraviti i skup oznaka u one-hot formatu kako bi testirali `CategoricalCrossentropy` gubitak. Razlika između `SparseCategoricalCrossentropy` i `CategoricalCrossentropy` gubitka je u ulaznom sučelju, a oba gubitka računaju isti gubitak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broj klasa odgovara broju klasa BEZ nadopune. Npr. 10 oznaka + 1 nadopuna -> num_classes = 10, a NE 11, inače izlaz ne odgovara!!!!\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadopuna je dobila oznaku klase 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nadopuna kreće od 9 vremenskog koraka\n",
    "y_test_one_hot[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testiranje modela sa `CategoricalCrossentropy` gubitkom**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_model = build_compiled_model(loss=tf.keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iz ovog se vidi da kod one-hot kodiranja ne možemo uvesti novu oznaku za nadopunu jer bi tada dimenzija izlaza bila `(None, None, 11)` što ne odgovara dimenzionalnosti izlaza modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/Identity:0' shape=(None, None, 10) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usporedba predikcije iz modela za uzorak sa nadopunom i bez nadopune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_preds_no_pad = cce_model.predict(np.expand_dims(X[0], axis=0))\n",
    "cce_preds_pad = cce_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09995514, 0.09969988, 0.10154733, 0.08104198, 0.09825476,\n",
       "         0.09161735, 0.10119843, 0.1195888 , 0.10263669, 0.10445961],\n",
       "        [0.09745356, 0.10515334, 0.10215287, 0.06633065, 0.09931501,\n",
       "         0.09968754, 0.1103203 , 0.10579999, 0.11028451, 0.10350222],\n",
       "        [0.09265828, 0.12462161, 0.10300116, 0.0677657 , 0.09832843,\n",
       "         0.10694425, 0.10555641, 0.09413032, 0.10330889, 0.10368495],\n",
       "        [0.10811888, 0.10450601, 0.08996869, 0.06142593, 0.08975842,\n",
       "         0.09444078, 0.16066778, 0.08711001, 0.10183918, 0.10216431],\n",
       "        [0.09558361, 0.11254033, 0.10109298, 0.05856425, 0.09472121,\n",
       "         0.09921907, 0.14864397, 0.09308051, 0.11157166, 0.0849824 ],\n",
       "        [0.09601758, 0.13491732, 0.10186077, 0.05381562, 0.09501486,\n",
       "         0.09428658, 0.15381056, 0.08110823, 0.1041777 , 0.08499079],\n",
       "        [0.10507908, 0.1462904 , 0.09642147, 0.0588892 , 0.09901195,\n",
       "         0.08644252, 0.1404274 , 0.06686535, 0.11928383, 0.08128884],\n",
       "        [0.09079527, 0.15090762, 0.09900653, 0.06926932, 0.0865592 ,\n",
       "         0.09316562, 0.14720824, 0.07550862, 0.11557291, 0.0720067 ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_preds_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na mjestim gdje je nadopuna model kao predikciju vraća 0.1, ali će biti pokazano da je gubitak na tim mjestima zanemaren tj. jednak je nuli ako primjenimo maskiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Provjera da je predikcija ista ako zanemarimo nadopunjena mjesta (sva poslije 8 opažanja)\n",
    "(cce_preds_pad[:,:8] == cce_preds_no_pad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iznos funkcije gubitka za uzorak sa nadopunom i bez nadopune, čovjek bi očekivao da su isti ali slijedi iznenađenje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_not_padded = y[0]\n",
    "y_not_padded = tf.keras.utils.to_categorical(y_not_padded, num_classes=10)\n",
    "y_not_padded = np.expand_dims(y_not_padded, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/sample - loss: 2.3552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.355224847793579"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_loss_no_pad = cce_model.evaluate(np.expand_dims(X[0], axis=0), y_not_padded)\n",
    "cce_loss_no_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/sample - loss: 0.4710\n"
     ]
    }
   ],
   "source": [
    "cce_loss_pad = cce_model.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postavlja se pitanja zašto postoji ova razlika u iznosu funkcije cilja kada znamo da se uzorci razlikuju samo u broju vremenskih koraka - bez nadopune broj koraka je 8, a sa njom je 40. Ako dobro pogledamo iznose funkcije gubitka vidjet ćemo da je njihov omjer upravo 40/8 = 5 !!!\n",
    "Kroz ručnu provjeru moguće je pokazati da je to upravo ono što se događa kod izračuna vrijednosti funkcije gubitka. Ovo nije očekivano ponašanje jer na taj način jedan te isti uzorak može različito djelovati na iznos funkcije gubitka ovisno o tome u kojoj mini grupi se nalazi. Ako se nalazi u mini grupi koja ima veću nadopunu tada će iznose funkcije cilja biti manje nego ako je u grupi koja ima manju nadopunu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.355224847793579"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ručna provjera - bez nadopune\n",
    "-np.sum(y_not_padded * np.log(cce_preds_no_pad))/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kada nema nadopune očekivanje funkcije gubitka u nazivniku ima (broj opažanja * broj vremenskih koraka) = 1 * 8 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47104496955871583"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ručna provjera - sa nadopunom (uz maskiranje zato je :8!!)\n",
    "-np.sum(y_test_one_hot[:,:8] * np.log(cce_preds_pad[:,:8]))/40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uz dodanu nadopunu očekivanje funkcije gubitka u nazivniku ima 40.\n",
    "Još jednom napominjem ovo nije očekivano ponašanje, ali na kraju nema utjecaj na učenje modela jer se ovaj iznos nigdje ne koristi, ali mi kao korisnici dobivamo pogrešnu informaciju."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U nastavku ću pokazati da naš model zaista u obzir uzima masku prilikom izračuna funkcije gubitka za nadopunjeni uzorak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.313113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Izračun iznosa funkcije gubitka za nadopunjeni uzorak bez maske\n",
    "no_mask_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "no_mask_loss(y_test_one_hot, cce_preds_pad).numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3131130218505858"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kako se došlo do ove brojke\n",
    "- np.sum(y_test_one_hot * np.log(cce_preds_pad))/40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovdje se vidi da su obzir uzete i one 0.1 vrijednosti koje model pokazuje za nadopune, te s obzirom da su oznake nadopuna iste kao i za klasu 0 sve je uračunato u gubitak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 81ms/sample - loss: 0.4710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47104495763778687"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Izračun iznosa funkcije gubitka za nadopunjeni uzorak sa maskom\n",
    "cce_model.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kada je maska uzeta u obzir ovo je iznos gubitka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testiranje modela sa `SparseCatgoricalCrossentropy` gubitkom**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model = build_compiled_model(loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predikcija iz modela sa nadopunjavanjem i bez nadopunjavanja\n",
    "sparse_model_preds_no_pad = sparse_model.predict(np.expand_dims(X[0], axis=0))\n",
    "sparse_model_preds_pad = sparse_model.predict(X_test)\n",
    "\n",
    "(sparse_model_preds_no_pad == sparse_model_preds_pad[:,:8]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09995514, 0.09969988, 0.10154733, 0.08104198, 0.09825476,\n",
       "         0.09161735, 0.10119843, 0.1195888 , 0.10263669, 0.10445961],\n",
       "        [0.09745356, 0.10515334, 0.10215287, 0.06633065, 0.09931501,\n",
       "         0.09968754, 0.1103203 , 0.10579999, 0.11028451, 0.10350222],\n",
       "        [0.09265828, 0.12462161, 0.10300116, 0.0677657 , 0.09832843,\n",
       "         0.10694425, 0.10555641, 0.09413032, 0.10330889, 0.10368495],\n",
       "        [0.10811888, 0.10450601, 0.08996869, 0.06142593, 0.08975842,\n",
       "         0.09444078, 0.16066778, 0.08711001, 0.10183918, 0.10216431],\n",
       "        [0.09558361, 0.11254033, 0.10109298, 0.05856425, 0.09472121,\n",
       "         0.09921907, 0.14864397, 0.09308051, 0.11157166, 0.0849824 ],\n",
       "        [0.09601758, 0.13491732, 0.10186077, 0.05381562, 0.09501486,\n",
       "         0.09428658, 0.15381056, 0.08110823, 0.1041777 , 0.08499079],\n",
       "        [0.10507908, 0.1462904 , 0.09642147, 0.0588892 , 0.09901195,\n",
       "         0.08644252, 0.1404274 , 0.06686535, 0.11928383, 0.08128884],\n",
       "        [0.09079527, 0.15090762, 0.09900653, 0.06926932, 0.0865592 ,\n",
       "         0.09316562, 0.14720824, 0.07550862, 0.11557291, 0.0720067 ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ],\n",
       "        [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "         0.1       , 0.1       , 0.1       , 0.1       , 0.1       ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model_preds_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo se uvjeriti da je predikcija iz cce_modela i sparse_modela ista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sparse_model_preds_pad == cce_preds_pad).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sada ćemo provjeriti iznos funkcije gubitka, za slučaj nadopune i bez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/sample - loss: 0.4710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47104495763778687"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gubitak je apsolutno isti kao i za cce model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bez maskiranja gubitak bi bio kako je prikazano dolje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.313113>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "sparse_loss(tf.convert_to_tensor(y_test), tf.convert_to_tensor(sparse_model_preds_pad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Važna napomena** kod primjene `SparseCategoricalCrossentropy` gubitka oznaka nadopune za y mora biti 0, probao sam i oznake poput -10 i 10, ali tada izlaz bude `nan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testiranje modela sa `SparseCategoricalCrossentropy` gubitkom i `tf.data.Dataset`-om za generiranje opažanja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idemo sada vidjeti da li ovo nadopunjavanje radi sa `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_build_dataset(X, y):\n",
    "    ds = tf.data.Dataset.from_generator(lambda: iter(zip(X, y)), \n",
    "                                       output_types=(tf.float32, tf.int32))\n",
    "    #U testnu funkciju stavit ću duljinu nadopuna na 40 i batch da bude 1\n",
    "    ds = ds.padded_batch(1, padded_shapes=([40, 2048], [40]), padding_values=(10., 0))\n",
    "    \n",
    "    return ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generiranje skupa podataka\n",
    "test_dataset = test_build_dataset(X[:2], y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 40, 2048), dtype=float32, numpy=\n",
      "array([[[5.7254905e-01, 2.3529412e-02, 2.0000000e-01, ...,\n",
      "         5.6862748e-01, 1.9215687e-01, 2.3529412e-01],\n",
      "        [6.6666670e-02, 5.6078434e-01, 4.7450981e-01, ...,\n",
      "         6.4313728e-01, 7.1372551e-01, 4.4705883e-01],\n",
      "        [3.9215689e-03, 9.8039217e-02, 8.0784315e-01, ...,\n",
      "         8.9411765e-01, 8.3137256e-01, 6.4705884e-01],\n",
      "        ...,\n",
      "        [1.0000000e+01, 1.0000000e+01, 1.0000000e+01, ...,\n",
      "         1.0000000e+01, 1.0000000e+01, 1.0000000e+01],\n",
      "        [1.0000000e+01, 1.0000000e+01, 1.0000000e+01, ...,\n",
      "         1.0000000e+01, 1.0000000e+01, 1.0000000e+01],\n",
      "        [1.0000000e+01, 1.0000000e+01, 1.0000000e+01, ...,\n",
      "         1.0000000e+01, 1.0000000e+01, 1.0000000e+01]]], dtype=float32)>, <tf.Tensor: shape=(1, 40), dtype=int32, numpy=\n",
      "array([[3, 9, 4, 5, 7, 2, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "for element in test_dataset.take(1): print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idemo ubaciti to jedno opažanje u model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 1s 1s/step - loss: 0.4710"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47104495763778687"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.evaluate(test_dataset.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juhu radi!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generiran skup podataka sa 2 opažanja, veličine: 0.09 MB\n",
      "(5, 2048) (5,)\n"
     ]
    }
   ],
   "source": [
    "X, y = video_data_generator(2, min_len=5, max_len=10)\n",
    "print(X[1].shape, y[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_build_dataset(X, y):\n",
    "    ds = tf.data.Dataset.from_generator(lambda: iter(zip(X, y)), \n",
    "                                       output_types=(tf.float32, tf.int32))\n",
    "    #U testnu funkciju stavit ću duljinu nadopuna na 40 i batch da bude 1\n",
    "    ds = ds.padded_batch(2, padded_shapes=([40, 2048], [40]), padding_values=(10., 0))\n",
    "    \n",
    "    return ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_build_dataset(X[:2], y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_model =  build_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = sparse_model(np.expand_dims(X[0], axis=0))\n",
    "preds_2 = sparse_model(np.expand_dims(X[1], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 10), dtype=float32, numpy=\n",
       "array([[[0.11001404, 0.10552107, 0.11830676, 0.07250454, 0.1300758 ,\n",
       "         0.08186158, 0.09162187, 0.08882565, 0.11286505, 0.0884036 ],\n",
       "        [0.10079003, 0.12395457, 0.11616632, 0.06710688, 0.12260108,\n",
       "         0.08293962, 0.11200565, 0.09302557, 0.10201432, 0.07939593],\n",
       "        [0.10915978, 0.11744958, 0.10832138, 0.05608214, 0.12959936,\n",
       "         0.0859175 , 0.11381278, 0.08148544, 0.1093683 , 0.08880377],\n",
       "        [0.09913972, 0.12073839, 0.10789456, 0.05156359, 0.09640401,\n",
       "         0.10551096, 0.14427568, 0.07249292, 0.10972534, 0.09225475],\n",
       "        [0.10000954, 0.12706769, 0.11117544, 0.04794908, 0.11150431,\n",
       "         0.09915347, 0.13889737, 0.07301044, 0.10933805, 0.08189458]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 10), dtype=float32, numpy=\n",
       "array([[[0.11031532, 0.10396454, 0.12393213, 0.08192398, 0.09528198,\n",
       "         0.11231874, 0.09937397, 0.08504782, 0.08851507, 0.09932642],\n",
       "        [0.10982328, 0.10981671, 0.13712107, 0.07679864, 0.09113602,\n",
       "         0.09647083, 0.10478106, 0.08727697, 0.0825411 , 0.10423431],\n",
       "        [0.10690726, 0.12967923, 0.13622552, 0.06271802, 0.09733277,\n",
       "         0.10469835, 0.1033857 , 0.08634533, 0.08352528, 0.08918259],\n",
       "        [0.09195168, 0.12523128, 0.12914595, 0.06617991, 0.08234257,\n",
       "         0.09659947, 0.14186278, 0.09416312, 0.07972792, 0.09279527],\n",
       "        [0.0993254 , 0.12681386, 0.11997992, 0.05336834, 0.08062448,\n",
       "         0.10304878, 0.12498306, 0.09708665, 0.10378332, 0.09098621],\n",
       "        [0.10185791, 0.1453045 , 0.12836175, 0.05977019, 0.09245957,\n",
       "         0.08283289, 0.12599616, 0.09342758, 0.09096382, 0.0790257 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 481ms/step - loss: 0.3230"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3229535222053528"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_oh = tf.keras.utils.to_categorical(y[0], num_classes=10)\n",
    "y_2_oh = tf.keras.utils.to_categorical(y[1], num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229535102844238"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((- np.sum(y_1_oh * np.log(preds_1))/40) + (- np.sum(y_2_oh * np.log(preds_2))/40))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radi i za više opažanja !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovako izgleda propagiranje maske kroz model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasked_sample = test_model.layers[0](test_sample)\n",
    "masked_sample = test_model.layers[1](unmasked_sample)\n",
    "masked_2 = test_model.layers[2](masked_sample)\n",
    "masked_3 = test_model.layers[3](masked_2)\n",
    "print(masked_3._keras_mask)\n",
    "print(masked_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testiranje 1d konvolucijskog modela, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poanta je pokazati kako riješiti problem maskiranja, jer 1d konvolucijski slojevi ne podržavaju maskiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_model_no_mask():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    srednji = tf.keras.layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(ulaz)\n",
    "    izlaz = tf.keras.layers.Conv1D(10, 1, activation=\"softmax\")(srednji)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz)\n",
    "    return model\n",
    "\n",
    "def tcn_model_MASK():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    \n",
    "    mask = tf.keras.layers.Lambda(lambda x: tf.reduce_any(tf.not_equal(x, 10.), axis=-1, keepdims=True))(ulaz)\n",
    "    mask_float = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.float32))(mask)\n",
    "    \n",
    "    srednji_1 = tf.keras.layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(ulaz)\n",
    "    srednji_2 = tf.keras.layers.Conv1D(10, 1, activation=\"softmax\")(srednji_1)\n",
    "    \n",
    "    izlaz = tf.keras.layers.multiply([srednji_2, mask_float])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_mask = tcn_model_no_mask()\n",
    "model_mask = tcn_model_MASK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for layer in model_mask.layers:\n",
    "    outputs.append(layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(None, None, 2048) dtype=float32>,\n",
       " <tf.Tensor 'conv1d/Identity:0' shape=(None, None, 32) dtype=float32>,\n",
       " <tf.Tensor 'lambda/Identity:0' shape=(None, None, 1) dtype=bool>,\n",
       " <tf.Tensor 'conv1d_1/Identity:0' shape=(None, None, 10) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1/Identity:0' shape=(None, None, 1) dtype=float32>,\n",
       " <tf.Tensor 'multiply/Identity:0' shape=(None, None, 10) dtype=float32>]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_model = tf.keras.Model(inputs=model_mask.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lambda is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer conv1d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 40, 2048), dtype=float64, numpy=\n",
       " array([[[ 0.82352942,  0.16078432,  0.78431374, ...,  0.99607843,\n",
       "           0.39215687,  0.01176471],\n",
       "         [ 0.8392157 ,  0.07450981,  0.70588237, ...,  0.71764708,\n",
       "           0.60784316,  0.36078432],\n",
       "         [ 0.69411767,  0.95294118,  0.67450982, ...,  0.65490198,\n",
       "           0.54901963,  0.67843139],\n",
       "         ...,\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ],\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ],\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ]]])>,\n",
       " <tf.Tensor: shape=(1, 40, 32), dtype=float32, numpy=\n",
       " array([[[ 1.2419618 ,  0.        ,  0.        , ...,  0.02798664,\n",
       "           0.3083924 ,  0.        ],\n",
       "         [ 0.7955876 ,  0.        ,  0.05573715, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 1.1923463 ,  0.        ,  0.03733695, ...,  0.        ,\n",
       "           0.7864176 ,  0.        ],\n",
       "         ...,\n",
       "         [24.745825  ,  0.        ,  0.        , ...,  0.        ,\n",
       "           5.12107   ,  0.        ],\n",
       "         [24.745825  ,  0.        ,  0.        , ...,  0.        ,\n",
       "           5.12107   ,  0.        ],\n",
       "         [20.473392  ,  0.        ,  3.4832222 , ...,  0.        ,\n",
       "           0.35066777,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 40, 1), dtype=bool, numpy=\n",
       " array([[[ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False]]])>,\n",
       " <tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       " array([[[5.99044524e-02, 6.77621737e-02, 2.03535259e-01, 4.91269454e-02,\n",
       "          8.40159953e-02, 1.43813416e-01, 1.26641601e-01, 9.62654427e-02,\n",
       "          6.44520894e-02, 1.04482569e-01],\n",
       "         [2.69218273e-02, 5.07885739e-02, 2.25267589e-01, 3.89914066e-02,\n",
       "          9.72983763e-02, 2.37147182e-01, 1.08519480e-01, 3.61363366e-02,\n",
       "          1.07288443e-01, 7.16407672e-02],\n",
       "         [5.74921183e-02, 4.42667417e-02, 2.42915615e-01, 5.41601777e-02,\n",
       "          1.09075740e-01, 1.74762249e-01, 1.30881682e-01, 5.53620160e-02,\n",
       "          5.03116660e-02, 8.07720423e-02],\n",
       "         [3.17528956e-02, 6.15120269e-02, 3.08201313e-01, 3.83319184e-02,\n",
       "          8.27065408e-02, 1.83121085e-01, 9.08005014e-02, 6.22726716e-02,\n",
       "          8.22003782e-02, 5.91007285e-02],\n",
       "         [4.57355343e-02, 3.62070575e-02, 2.46231586e-01, 5.68595529e-02,\n",
       "          1.18033223e-01, 1.62055284e-01, 1.30843982e-01, 6.12905882e-02,\n",
       "          6.28749728e-02, 7.98681527e-02],\n",
       "         [3.77154648e-02, 4.96413410e-02, 3.44123513e-01, 2.27096546e-02,\n",
       "          7.51068965e-02, 2.22017437e-01, 8.69101286e-02, 4.47618067e-02,\n",
       "          4.81163673e-02, 6.88973591e-02],\n",
       "         [4.07602228e-02, 4.89627458e-02, 3.76527488e-01, 3.59407552e-02,\n",
       "          6.95827678e-02, 1.53634697e-01, 1.22326933e-01, 4.57148105e-02,\n",
       "          5.37358262e-02, 5.28137535e-02],\n",
       "         [5.64434458e-06, 1.55319212e-05, 3.05555582e-01, 2.09877733e-02,\n",
       "          1.17129798e-03, 1.66018843e-03, 6.69764042e-01, 2.27650776e-06,\n",
       "          8.22269998e-04, 1.53701294e-05],\n",
       "         [4.03948533e-12, 2.12571571e-10, 9.99801219e-01, 1.40127141e-13,\n",
       "          3.32705849e-06, 1.95429588e-04, 6.51612364e-09, 1.10061932e-10,\n",
       "          1.44355117e-09, 3.44519058e-09],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [7.11198211e-10, 6.13781470e-10, 4.57846344e-01, 1.15655109e-12,\n",
       "          3.11057966e-06, 5.42144418e-01, 1.47430470e-07, 5.01924706e-06,\n",
       "          6.28886667e-08, 9.12710391e-07]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 40, 1), dtype=float32, numpy=\n",
       " array([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       " array([[[5.9904452e-02, 6.7762174e-02, 2.0353526e-01, 4.9126945e-02,\n",
       "          8.4015995e-02, 1.4381342e-01, 1.2664160e-01, 9.6265443e-02,\n",
       "          6.4452089e-02, 1.0448257e-01],\n",
       "         [2.6921827e-02, 5.0788574e-02, 2.2526759e-01, 3.8991407e-02,\n",
       "          9.7298376e-02, 2.3714718e-01, 1.0851948e-01, 3.6136337e-02,\n",
       "          1.0728844e-01, 7.1640767e-02],\n",
       "         [5.7492118e-02, 4.4266742e-02, 2.4291562e-01, 5.4160178e-02,\n",
       "          1.0907574e-01, 1.7476225e-01, 1.3088168e-01, 5.5362016e-02,\n",
       "          5.0311666e-02, 8.0772042e-02],\n",
       "         [3.1752896e-02, 6.1512027e-02, 3.0820131e-01, 3.8331918e-02,\n",
       "          8.2706541e-02, 1.8312109e-01, 9.0800501e-02, 6.2272672e-02,\n",
       "          8.2200378e-02, 5.9100728e-02],\n",
       "         [4.5735534e-02, 3.6207058e-02, 2.4623159e-01, 5.6859553e-02,\n",
       "          1.1803322e-01, 1.6205528e-01, 1.3084398e-01, 6.1290588e-02,\n",
       "          6.2874973e-02, 7.9868153e-02],\n",
       "         [3.7715465e-02, 4.9641341e-02, 3.4412351e-01, 2.2709655e-02,\n",
       "          7.5106896e-02, 2.2201744e-01, 8.6910129e-02, 4.4761807e-02,\n",
       "          4.8116367e-02, 6.8897359e-02],\n",
       "         [4.0760223e-02, 4.8962746e-02, 3.7652749e-01, 3.5940755e-02,\n",
       "          6.9582768e-02, 1.5363470e-01, 1.2232693e-01, 4.5714810e-02,\n",
       "          5.3735826e-02, 5.2813753e-02],\n",
       "         [5.6443446e-06, 1.5531921e-05, 3.0555558e-01, 2.0987773e-02,\n",
       "          1.1712980e-03, 1.6601884e-03, 6.6976404e-01, 2.2765078e-06,\n",
       "          8.2227000e-04, 1.5370129e-05],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00]]], dtype=float32)>]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjera da li modeli imaju isti broj parametara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 32)          196640    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 10)          330       \n",
      "=================================================================\n",
      "Total params: 196,970\n",
      "Trainable params: 196,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_mask.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 2048)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 32)     196640      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 10)     330         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 1)      0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 10)     0           conv1d_1[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 196,970\n",
      "Trainable params: 196,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_mask.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_no_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjera da li su modelima inicijalizirane iste težine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1_weights = []\n",
    "for layer in model_no_mask.layers:\n",
    "    if layer.weights:\n",
    "        bias1_weights.append(layer.weights[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias2_weights = []\n",
    "for layer in model_mask.layers:\n",
    "    if layer.weights:\n",
    "        bias2_weights.append(layer.weights[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bias1_weights,bias2_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_weights = []\n",
    "for layer in model_no_mask.layers:\n",
    "    if layer.weights:\n",
    "        m1_weights.append(layer.weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_weights = []\n",
    "for layer in model_mask.layers:\n",
    "    if layer.weights:\n",
    "        m2_weights.append(layer.weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for w1, w2 in zip(m1_weights, m2_weights):\n",
    "    print((w1 == w2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "del w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjera izlaza iz oba modela za nenadopunjeno opažanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.expand_dims(X[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[test_X == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 10), dtype=float32, numpy=\n",
       "array([[[0.05990445, 0.06776217, 0.20353526, 0.04912695, 0.084016  ,\n",
       "         0.14381342, 0.1266416 , 0.09626544, 0.06445209, 0.10448257],\n",
       "        [0.02692183, 0.05078857, 0.22526759, 0.03899141, 0.09729838,\n",
       "         0.23714718, 0.10851948, 0.03613634, 0.10728844, 0.07164077],\n",
       "        [0.05749212, 0.04426674, 0.24291562, 0.05416018, 0.10907574,\n",
       "         0.17476225, 0.13088168, 0.05536202, 0.05031167, 0.08077204],\n",
       "        [0.0317529 , 0.06151203, 0.3082013 , 0.03833192, 0.08270654,\n",
       "         0.18312109, 0.0908005 , 0.06227267, 0.08220038, 0.05910073],\n",
       "        [0.04573553, 0.03620706, 0.24623159, 0.05685955, 0.11803322,\n",
       "         0.16205528, 0.13084398, 0.06129059, 0.06287497, 0.07986815],\n",
       "        [0.03771546, 0.04964134, 0.3441235 , 0.02270965, 0.0751069 ,\n",
       "         0.22201744, 0.08691013, 0.04476181, 0.04811637, 0.06889736],\n",
       "        [0.04076022, 0.04896275, 0.3765275 , 0.03594076, 0.06958277,\n",
       "         0.1536347 , 0.12232693, 0.04571481, 0.05373583, 0.05281375],\n",
       "        [0.03839651, 0.05472557, 0.10751758, 0.04085652, 0.15572351,\n",
       "         0.18172683, 0.07435789, 0.14332241, 0.08138382, 0.12198933]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8, 10), dtype=float32, numpy=\n",
       "array([[[0.05990445, 0.06776217, 0.20353526, 0.04912695, 0.084016  ,\n",
       "         0.14381342, 0.1266416 , 0.09626544, 0.06445209, 0.10448257],\n",
       "        [0.02692183, 0.05078857, 0.22526759, 0.03899141, 0.09729838,\n",
       "         0.23714718, 0.10851948, 0.03613634, 0.10728844, 0.07164077],\n",
       "        [0.05749212, 0.04426674, 0.24291562, 0.05416018, 0.10907574,\n",
       "         0.17476225, 0.13088168, 0.05536202, 0.05031167, 0.08077204],\n",
       "        [0.0317529 , 0.06151203, 0.3082013 , 0.03833192, 0.08270654,\n",
       "         0.18312109, 0.0908005 , 0.06227267, 0.08220038, 0.05910073],\n",
       "        [0.04573553, 0.03620706, 0.24623159, 0.05685955, 0.11803322,\n",
       "         0.16205528, 0.13084398, 0.06129059, 0.06287497, 0.07986815],\n",
       "        [0.03771546, 0.04964134, 0.3441235 , 0.02270965, 0.0751069 ,\n",
       "         0.22201744, 0.08691013, 0.04476181, 0.04811637, 0.06889736],\n",
       "        [0.04076022, 0.04896275, 0.3765275 , 0.03594076, 0.06958277,\n",
       "         0.1536347 , 0.12232693, 0.04571481, 0.05373583, 0.05281375],\n",
       "        [0.03839651, 0.05472557, 0.10751758, 0.04085652, 0.15572351,\n",
       "         0.18172683, 0.07435789, 0.14332241, 0.08138382, 0.12198933]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mask(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_all(model_no_mask(test_X) == model_mask(test_X)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zašto izlazi iz ova dva modela nisu isti?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kada sam definirao model_mask, sa `Masking` layerom nisam dobivao iste izlaze iz oba modela iz razloga što taj sloj vraća svoj ulaz, sa onim komponentama koje odgovaraju mask value u potpunosti u zadnjoj dimenziji na 0.\n",
    "\n",
    "Zabluda je da vraća masku, to možemo dobiti ako eksplicitno na tom sloju pozovemo metodu `compute_mask` tada vraća `bool` tenzor, ali dimenzije 2D (istisne zadnju dimenziju, zbog definicije `tf.reduce_all` u `Masking` sloju gdje je `keepdims=False`), te onda naknadno je potrebno dodavati tu dimenziju.\n",
    "\n",
    "Jednostavniji pristup je definirati `Lambda` sloj i kroz njega riješiti pitanje prosljeđivanja maske."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fora kako vidjeti izlaze iz svakog sloja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_layer_outputs = [layer.output for layer in model_mask.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(None, None, 2048) dtype=float32>,\n",
       " <tf.Tensor 'NotEqual:0' shape=(None, None, 2048) dtype=bool>,\n",
       " <tf.Tensor 'conv1d/Identity:0' shape=(None, None, 32) dtype=float32>,\n",
       " <tf.Tensor 'Any:0' shape=(None, None) dtype=bool>,\n",
       " <tf.Tensor 'conv1d_1/Identity:0' shape=(None, None, 10) dtype=float32>,\n",
       " <tf.Tensor 'lambda/Identity:0' shape=(None, None, 1) dtype=float32>,\n",
       " <tf.Tensor 'multiply/Identity:0' shape=(None, None, 10) dtype=float32>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_model_layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter1_model = tf.keras.Model(inputs = model_mask.input, outputs=mask_model_layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 8, 2048), dtype=float32, numpy=\n",
       " array([[[0.8235294 , 0.16078432, 0.78431374, ..., 0.99607843,\n",
       "          0.39215687, 0.01176471],\n",
       "         [0.8392157 , 0.07450981, 0.7058824 , ..., 0.7176471 ,\n",
       "          0.60784316, 0.36078432],\n",
       "         [0.69411767, 0.9529412 , 0.6745098 , ..., 0.654902  ,\n",
       "          0.54901963, 0.6784314 ],\n",
       "         ...,\n",
       "         [0.00784314, 0.38039216, 0.972549  , ..., 0.34117648,\n",
       "          0.34901962, 0.654902  ],\n",
       "         [0.7294118 , 0.7176471 , 0.9254902 , ..., 0.8039216 ,\n",
       "          0.99215686, 0.07450981],\n",
       "         [0.11764706, 0.7411765 , 0.34901962, ..., 0.04313726,\n",
       "          0.654902  , 0.63529414]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 2048), dtype=bool, numpy=\n",
       " array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]])>,\n",
       " <tf.Tensor: shape=(1, 8, 32), dtype=float32, numpy=\n",
       " array([[[1.24196184e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 2.97047675e-01, 3.50926161e-01, 3.89744669e-01,\n",
       "          6.53967500e-01, 3.53088200e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 6.54169619e-01, 0.00000000e+00, 2.39583790e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.90715855e-02, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.45871449e-01,\n",
       "          2.74727672e-01, 5.79566896e-01, 0.00000000e+00, 3.20618391e-01,\n",
       "          0.00000000e+00, 2.79866401e-02, 3.08392406e-01, 0.00000000e+00],\n",
       "         [7.95587599e-01, 0.00000000e+00, 5.57371527e-02, 1.37588230e-03,\n",
       "          1.10243425e-01, 7.01365173e-01, 9.93764460e-01, 7.99165428e-01,\n",
       "          8.76035333e-01, 0.00000000e+00, 1.73791301e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.98467451e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.53521800e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.73773301e+00,\n",
       "          8.51357877e-01, 5.62531650e-01, 2.30000064e-01, 3.01433295e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.19234633e+00, 0.00000000e+00, 3.73369493e-02, 0.00000000e+00,\n",
       "          1.34400263e-01, 3.50741327e-01, 6.07315004e-02, 1.69094038e+00,\n",
       "          8.54648769e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.20212656e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.23025143e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.28208244e+00,\n",
       "          6.83597550e-02, 0.00000000e+00, 0.00000000e+00, 7.82104060e-02,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.86417603e-01, 0.00000000e+00],\n",
       "         [1.19539940e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.69909739e-01, 9.92768168e-01,\n",
       "          5.30471914e-02, 0.00000000e+00, 5.34254134e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.21755564e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.33329892e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.18108237e+00,\n",
       "          1.13285565e+00, 8.21868777e-01, 7.48563945e-01, 5.27779579e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.24671169e-02, 0.00000000e+00],\n",
       "         [9.84659970e-01, 0.00000000e+00, 4.08888876e-01, 0.00000000e+00,\n",
       "          5.06831586e-01, 5.23271680e-01, 4.56405506e-02, 1.85159910e+00,\n",
       "          5.75761139e-01, 0.00000000e+00, 4.54304516e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.87582743e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.48614454e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.70171201e+00,\n",
       "          4.28682148e-01, 4.68428403e-01, 6.10953309e-02, 3.82689089e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 5.29503584e-01, 0.00000000e+00],\n",
       "         [1.08089709e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 5.33590674e-01, 1.15386665e+00, 1.34280539e+00,\n",
       "          3.33586127e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.91105747e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.78866613e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.12896109e+00,\n",
       "          6.83171988e-01, 8.86020124e-01, 0.00000000e+00, 8.08037937e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.57377124e-01, 0.00000000e+00],\n",
       "         [1.49252236e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          1.60178423e-01, 0.00000000e+00, 5.16844809e-01, 1.21400297e+00,\n",
       "          7.32934654e-01, 0.00000000e+00, 5.03824472e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.72509193e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.73880315e+00,\n",
       "          7.64789209e-02, 3.09142083e-01, 7.41478086e-01, 3.56398344e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 9.94582593e-01, 0.00000000e+00],\n",
       "         [7.51865566e-01, 0.00000000e+00, 2.52249956e-01, 6.54837370e-01,\n",
       "          1.19411516e+00, 7.54929245e-01, 3.38743120e-01, 4.73358065e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.12549174e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "          7.12385699e-02, 0.00000000e+00, 3.57419193e-01, 0.00000000e+00,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.63925514e-01, 1.35606015e+00,\n",
       "          9.02937829e-01, 0.00000000e+00, 0.00000000e+00, 1.06996723e-01,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8), dtype=bool, numpy=array([[ True,  True,  True,  True,  True,  True,  True,  True]])>,\n",
       " <tf.Tensor: shape=(1, 8, 10), dtype=float32, numpy=\n",
       " array([[[0.05990445, 0.06776217, 0.20353526, 0.04912695, 0.084016  ,\n",
       "          0.14381342, 0.1266416 , 0.09626544, 0.06445209, 0.10448257],\n",
       "         [0.02692183, 0.05078857, 0.22526759, 0.03899141, 0.09729838,\n",
       "          0.23714718, 0.10851948, 0.03613634, 0.10728844, 0.07164077],\n",
       "         [0.05749212, 0.04426674, 0.24291562, 0.05416018, 0.10907574,\n",
       "          0.17476225, 0.13088168, 0.05536202, 0.05031167, 0.08077204],\n",
       "         [0.0317529 , 0.06151203, 0.3082013 , 0.03833192, 0.08270654,\n",
       "          0.18312109, 0.0908005 , 0.06227267, 0.08220038, 0.05910073],\n",
       "         [0.04573553, 0.03620706, 0.24623159, 0.05685955, 0.11803322,\n",
       "          0.16205528, 0.13084398, 0.06129059, 0.06287497, 0.07986815],\n",
       "         [0.03771546, 0.04964134, 0.3441235 , 0.02270965, 0.0751069 ,\n",
       "          0.22201744, 0.08691013, 0.04476181, 0.04811637, 0.06889736],\n",
       "         [0.04076022, 0.04896275, 0.3765275 , 0.03594076, 0.06958277,\n",
       "          0.1536347 , 0.12232693, 0.04571481, 0.05373583, 0.05281375],\n",
       "         [0.03839651, 0.05472557, 0.10751758, 0.04085652, 0.15572351,\n",
       "          0.18172683, 0.07435789, 0.14332241, 0.08138382, 0.12198933]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 1), dtype=float32, numpy=\n",
       " array([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 8, 10), dtype=float32, numpy=\n",
       " array([[[0.05990445, 0.06776217, 0.20353526, 0.04912695, 0.084016  ,\n",
       "          0.14381342, 0.1266416 , 0.09626544, 0.06445209, 0.10448257],\n",
       "         [0.02692183, 0.05078857, 0.22526759, 0.03899141, 0.09729838,\n",
       "          0.23714718, 0.10851948, 0.03613634, 0.10728844, 0.07164077],\n",
       "         [0.05749212, 0.04426674, 0.24291562, 0.05416018, 0.10907574,\n",
       "          0.17476225, 0.13088168, 0.05536202, 0.05031167, 0.08077204],\n",
       "         [0.0317529 , 0.06151203, 0.3082013 , 0.03833192, 0.08270654,\n",
       "          0.18312109, 0.0908005 , 0.06227267, 0.08220038, 0.05910073],\n",
       "         [0.04573553, 0.03620706, 0.24623159, 0.05685955, 0.11803322,\n",
       "          0.16205528, 0.13084398, 0.06129059, 0.06287497, 0.07986815],\n",
       "         [0.03771546, 0.04964134, 0.3441235 , 0.02270965, 0.0751069 ,\n",
       "          0.22201744, 0.08691013, 0.04476181, 0.04811637, 0.06889736],\n",
       "         [0.04076022, 0.04896275, 0.3765275 , 0.03594076, 0.06958277,\n",
       "          0.1536347 , 0.12232693, 0.04571481, 0.05373583, 0.05281375],\n",
       "         [0.03839651, 0.05472557, 0.10751758, 0.04085652, 0.15572351,\n",
       "          0.18172683, 0.07435789, 0.14332241, 0.08138382, 0.12198933]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter1_model(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 40, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.reduce_any(tf.not_equal(X_test, 10.), axis=-1, keepdims=True), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usporedba izlaza iz modela sa nadopunjenim uzorcima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       "array([[[5.99044524e-02, 6.77621737e-02, 2.03535259e-01, 4.91269454e-02,\n",
       "         8.40159953e-02, 1.43813416e-01, 1.26641601e-01, 9.62654427e-02,\n",
       "         6.44520894e-02, 1.04482569e-01],\n",
       "        [2.69218273e-02, 5.07885739e-02, 2.25267589e-01, 3.89914066e-02,\n",
       "         9.72983763e-02, 2.37147182e-01, 1.08519480e-01, 3.61363366e-02,\n",
       "         1.07288443e-01, 7.16407672e-02],\n",
       "        [5.74921183e-02, 4.42667417e-02, 2.42915615e-01, 5.41601777e-02,\n",
       "         1.09075740e-01, 1.74762249e-01, 1.30881682e-01, 5.53620160e-02,\n",
       "         5.03116660e-02, 8.07720423e-02],\n",
       "        [3.17528956e-02, 6.15120269e-02, 3.08201313e-01, 3.83319184e-02,\n",
       "         8.27065408e-02, 1.83121085e-01, 9.08005014e-02, 6.22726716e-02,\n",
       "         8.22003782e-02, 5.91007285e-02],\n",
       "        [4.57355343e-02, 3.62070575e-02, 2.46231586e-01, 5.68595529e-02,\n",
       "         1.18033223e-01, 1.62055284e-01, 1.30843982e-01, 6.12905882e-02,\n",
       "         6.28749728e-02, 7.98681527e-02],\n",
       "        [3.77154648e-02, 4.96413410e-02, 3.44123513e-01, 2.27096546e-02,\n",
       "         7.51068965e-02, 2.22017437e-01, 8.69101286e-02, 4.47618067e-02,\n",
       "         4.81163673e-02, 6.88973591e-02],\n",
       "        [4.07602228e-02, 4.89627458e-02, 3.76527488e-01, 3.59407552e-02,\n",
       "         6.95827678e-02, 1.53634697e-01, 1.22326933e-01, 4.57148105e-02,\n",
       "         5.37358262e-02, 5.28137535e-02],\n",
       "        [5.64434458e-06, 1.55319212e-05, 3.05555582e-01, 2.09877733e-02,\n",
       "         1.17129798e-03, 1.66018843e-03, 6.69764042e-01, 2.27650776e-06,\n",
       "         8.22269998e-04, 1.53701294e-05],\n",
       "        [4.03948533e-12, 2.12571571e-10, 9.99801219e-01, 1.40127141e-13,\n",
       "         3.32705849e-06, 1.95429588e-04, 6.51612364e-09, 1.10061932e-10,\n",
       "         1.44355117e-09, 3.44519058e-09],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "         3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "         6.62872209e-13, 1.40184105e-14],\n",
       "        [7.11198211e-10, 6.13781470e-10, 4.57846344e-01, 1.15655109e-12,\n",
       "         3.11057966e-06, 5.42144418e-01, 1.47430470e-07, 5.01924706e-06,\n",
       "         6.28886667e-08, 9.12710391e-07]]], dtype=float32)>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask(tf.cast(X_test, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       "array([[[5.9904452e-02, 6.7762174e-02, 2.0353526e-01, 4.9126945e-02,\n",
       "         8.4015995e-02, 1.4381342e-01, 1.2664160e-01, 9.6265443e-02,\n",
       "         6.4452089e-02, 1.0448257e-01],\n",
       "        [2.6921827e-02, 5.0788574e-02, 2.2526759e-01, 3.8991407e-02,\n",
       "         9.7298376e-02, 2.3714718e-01, 1.0851948e-01, 3.6136337e-02,\n",
       "         1.0728844e-01, 7.1640767e-02],\n",
       "        [5.7492118e-02, 4.4266742e-02, 2.4291562e-01, 5.4160178e-02,\n",
       "         1.0907574e-01, 1.7476225e-01, 1.3088168e-01, 5.5362016e-02,\n",
       "         5.0311666e-02, 8.0772042e-02],\n",
       "        [3.1752896e-02, 6.1512027e-02, 3.0820131e-01, 3.8331918e-02,\n",
       "         8.2706541e-02, 1.8312109e-01, 9.0800501e-02, 6.2272672e-02,\n",
       "         8.2200378e-02, 5.9100728e-02],\n",
       "        [4.5735534e-02, 3.6207058e-02, 2.4623159e-01, 5.6859553e-02,\n",
       "         1.1803322e-01, 1.6205528e-01, 1.3084398e-01, 6.1290588e-02,\n",
       "         6.2874973e-02, 7.9868153e-02],\n",
       "        [3.7715465e-02, 4.9641341e-02, 3.4412351e-01, 2.2709655e-02,\n",
       "         7.5106896e-02, 2.2201744e-01, 8.6910129e-02, 4.4761807e-02,\n",
       "         4.8116367e-02, 6.8897359e-02],\n",
       "        [4.0760223e-02, 4.8962746e-02, 3.7652749e-01, 3.5940755e-02,\n",
       "         6.9582768e-02, 1.5363470e-01, 1.2232693e-01, 4.5714810e-02,\n",
       "         5.3735826e-02, 5.2813753e-02],\n",
       "        [5.6443446e-06, 1.5531921e-05, 3.0555558e-01, 2.0987773e-02,\n",
       "         1.1712980e-03, 1.6601884e-03, 6.6976404e-01, 2.2765078e-06,\n",
       "         8.2227000e-04, 1.5370129e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mask(tf.cast(X_test, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Izračun funkcije gubitka iz ovih modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kompajliranje mask i no_mask modela\n",
    "model_mask.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "model_no_mask.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 40, 2048), (1, 8))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test[:,:8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 291ms/sample - loss: 2.4075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4074602127075195"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Izračun gubitka sa ne nadopunjenim opažanjem\n",
    "model_mask.evaluate(X_test[:,:8,:], y_test[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 289ms/sample - loss: 2.4075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4074602127075195"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask.evaluate(X_test[:,:8,:], y_test[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 169ms/sample - loss: 2.5277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.527740001678467"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Izračun gubitka sa nadopunjenim opažanjem\n",
    "model_mask.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 200ms/sample - loss: 13.5801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.580148696899414"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.04370653e-02, 9.31522995e-02, 1.99914932e-01, 3.33367959e-02,\n",
       "         1.16511151e-01, 1.55505493e-01, 7.51380995e-02, 9.24233571e-02,\n",
       "         6.47187904e-02, 1.38861999e-01],\n",
       "        [7.34077618e-02, 4.23050113e-02, 3.05110008e-01, 2.40864977e-02,\n",
       "         6.76638633e-02, 2.17707217e-01, 1.18670329e-01, 5.03504500e-02,\n",
       "         4.45234068e-02, 5.61755486e-02],\n",
       "        [5.77752106e-02, 6.13865107e-02, 2.07607314e-01, 5.19828871e-02,\n",
       "         8.69373977e-02, 1.78612456e-01, 1.58805996e-01, 6.99861571e-02,\n",
       "         4.85016070e-02, 7.84044415e-02],\n",
       "        [3.89075764e-02, 7.37654418e-02, 3.32891375e-01, 4.04097401e-02,\n",
       "         5.20612001e-02, 1.78610712e-01, 8.82541537e-02, 7.25515410e-02,\n",
       "         5.70828579e-02, 6.54654503e-02],\n",
       "        [7.65989353e-06, 2.00720515e-05, 2.78632879e-01, 2.46261563e-02,\n",
       "         9.21242230e-04, 1.63094560e-03, 6.92873359e-01, 4.21523100e-06,\n",
       "         1.26525993e-03, 1.82434924e-05],\n",
       "        [1.84426389e-12, 1.38674253e-10, 9.99869466e-01, 5.63796039e-14,\n",
       "         1.65470055e-06, 1.28896863e-04, 2.93817237e-09, 4.56987885e-11,\n",
       "         7.94957156e-10, 1.40920198e-09],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [5.66419063e-14, 2.55144450e-14, 9.99456823e-01, 1.96589895e-18,\n",
       "         3.64648978e-10, 5.43221366e-04, 3.95373956e-09, 1.16666178e-15,\n",
       "         6.62873510e-13, 1.40184385e-14],\n",
       "        [7.11198545e-10, 6.13781748e-10, 4.57846105e-01, 1.15654936e-12,\n",
       "         3.11057784e-06, 5.42144656e-01, 1.47430683e-07, 5.01923932e-06,\n",
       "         6.28886312e-08, 9.12710789e-07]]], dtype=float32)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manualni izračun gubitka za nadopunjeni i nenadopunjeni uzorak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Nenadopunjeni opažanje - predikcija\n",
    "preds_no_mask = model_no_mask.predict(X_test[:,:8,:])\n",
    "preds_mask = model_mask.predict(X_test[:,:8,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4074602127075195\n",
      "2.4074602127075195\n"
     ]
    }
   ],
   "source": [
    "oh_y_8 = tf.keras.utils.to_categorical(y_test[:,:8])\n",
    "print(-np.sum(oh_y_8 * np.log(preds_no_mask))/8)\n",
    "print(-np.sum(oh_y_8 * np.log(preds_mask))/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.4074602>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "sparse_loss(tf.convert_to_tensor(y_test[:,:8]), tf.convert_to_tensor(preds_no_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.4074605>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce_loss(oh_y_8, preds_no_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.4074602>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "sparse_loss(tf.convert_to_tensor(y_test[:,:8]), tf.convert_to_tensor(preds_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.4074605>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce_loss(oh_y_8, preds_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.82352942, 0.16078432, 0.78431374, ..., 0.99607843,\n",
       "         0.39215687, 0.01176471],\n",
       "        [0.8392157 , 0.07450981, 0.70588237, ..., 0.71764708,\n",
       "         0.60784316, 0.36078432],\n",
       "        [0.69411767, 0.95294118, 0.67450982, ..., 0.65490198,\n",
       "         0.54901963, 0.67843139],\n",
       "        ...,\n",
       "        [0.00784314, 0.38039216, 0.97254902, ..., 0.34117648,\n",
       "         0.34901962, 0.65490198],\n",
       "        [0.72941178, 0.71764708, 0.9254902 , ..., 0.80392158,\n",
       "         0.99215686, 0.07450981],\n",
       "        [0.11764706, 0.74117649, 0.34901962, ..., 0.04313726,\n",
       "         0.65490198, 0.63529414]]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nadopunjena opažanje - predikcija\n",
    "preds_no_mask = model_no_mask.predict(X_test)\n",
    "preds_mask = model_mask.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True]]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_no_mask[:,:8] == preds_mask[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 81ms/sample - loss: 13.5801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.580148696899414"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_mask.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 83ms/sample - loss: 2.5277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.527740001678467"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mask.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001, 1.       , 1.0000001, 1.       , 0.9999999, 1.       ,\n",
       "        1.       , 0.9999998, 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       , 0.       , 0.       , 0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_mask.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovo je problem jer će kod izračuna f. gubitka np.log(0) = nan !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.580149>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "sparse_loss(tf.convert_to_tensor(y_test), tf.convert_to_tensor(preds_no_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.580149>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce_loss(oh_y_40, preds_no_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConv1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaskConv1D, self).__init__(**kwargs)\n",
    "        #Omogućava propagiranje maske\n",
    "        self.supports_masking = True\n",
    "    \n",
    "    #def call(self, inputs):\n",
    "        #return inputs\n",
    "    #Omogućava prijem maske\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        masked_inputs = inputs * broadcast_float_mask   \n",
    "        return masked_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1D_MASK_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    \n",
    "    #mask = tf.keras.layers.Masking(mask_value=10.).compute_mask(ulaz)\n",
    "    mask = tf.keras.layers.Lambda(lambda x: tf.reduce_any(tf.not_equal(x, 10.), axis=-1))(ulaz)\n",
    "    \n",
    "    srednji_1 = tf.keras.layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(ulaz)\n",
    "    srednji_2 = tf.keras.layers.Conv1D(10, 1, activation=\"softmax\")(srednji_1)\n",
    "    \n",
    "    izlaz = MaskConv1D()(srednji_2, mask=mask)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = conv_1D_MASK_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 2048)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 32)     196640      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 10)     330         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mask_conv1d (MaskConv1D)        (None, None, 10)     0           conv1d_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 196,970\n",
      "Trainable params: 196,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAFgCAYAAABe2gluAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3df2zU9f0H8OfZlulGBAe2wzAWtWNTw9gyfxTnD2jYApjPCYwy2lqZDbLrAgb2Qwm7i4mtMrc2MWgsXo2LI+011KDpSTuRMsYMPdgwZUy3QmXeSXR31nCnDmKP+v7+wff98X73rr27z+fe93wkDdzn5+ven88973Pvz+c+ZxFCCBARkZIuM7oAIiLKHYY8EZHCGPJERApjyBMRKazU6ALIOG63G7t37za6DKKkGhoaoGma0WUUNB7JF7Hu7m709PQYXQZRQj09Peju7ja6jILHI/kiV1dXh87OTqPLIIpTX19vdAlK4JE8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyFNGHA4HHA6H0WUQUZoY8lRQQqEQLBbLpOf1eDzo6OiA1Wqd1DIsFkvCPyPEtoWZaiPz4I+GUEaam5sNXf/hw4cnPW9raysAoKWlZdLLEEIgFAph5syZAIBgMIgZM2ZMenlTEdsWQggEAgFUVFQAMLY2Mg+GPBWMUCiEjo6OSc8v36CmEvIAooLTqBBN1hbl5eX6/xnwBLC7hjIQCATQ3d2td3XEPna73bBYLLBarfD5fPo0brdbn6ajowMWiwVNTU04deqUvuxE3Quxw1pbW+F2u6PGZdtkzzkUYlvINwo5v8PhQCAQQFtbW9T62tra9Hkix0U+LzncarXi4MGDcc83FAqhqamJ53OMIKho1dXVibq6urSn1zRNABByt4l8PDg4KIQQwuv1CgDCZrMJIYQ+PnKaYDAobDabACCGh4eFEEL4/f6oZUcuK3JY7OPJSLUMu90u7HZ7xsswU1uk20ZyvX6/P67WwcHBqMeRNE0Tfr9fr1XTNOFyuYQQQgwMDAgAYmhoKK5NhoaGEi4vmUz3T0qMIV/EJvMiSido0plmaGhIABCtra1TXlamcrUMs7RFus/PbrdHhW7sfK2trQKA8Hq9UbXKQBdCCJfLlbBO+UYplxkMBiesJxZDPjvYXUOGWLhwIQDgV7/6lcGVGM+otmhubkZ7ezt8Pl9Ul4y0dOlSAMBrr72mDztw4ABuv/12/XFXVxeA+O6k2PMePD9gHIY8URHr6OjApk2boGla3LiFCxfCZrNh48aNCIVCCIVCGBkZwbx58/Rp5HkBcalXIOqPzIEhT4ay2WxGl2Aa+WqLpqYmAEB3dzc2btyIZ555BvPnz09ZU39/Pw4fPoz169cnnC7yxDGZC0OeDCFDYcWKFQZXYrx8toXH48Hdd98NAKitrQWAqCPzWPJovra2Fh0dHaiqqooa73Q6AQC7d+9GKBQC8MXVNmQODHlKWyAQiPp/5GP5Apf/xk4PXDpylNPs3r0bmqZFdRPIo0YZeh6PRx8njz7l9JMNksj6Iv8vpXMJZaJlmKUtYtcTyePxYNGiRbjhhhui5vf5fFFH4rHLkEfvibp07r33XgCX+uBnzpwJi8WCiooK1NTUpKyF8sjQ075kqEyvXkDEJYCJ/hJNEzks8rI6p9MZd8WF1+vVx/f29gohhH55nrxkT16JYrfb9WFTrT/SRJdQTtQGRrZFurXJdcXOL6+2ibyaRtI0Tb/EM5bX6xV2u12/5FLOH7lOTdMm3D6xeHVNdliE4BmSYlVfXw8A6OzszOl65BUX3NUKsy1CoRC2bduG9vb2vK43X/un6thdQ0Qp7dmzBzU1NUaXQZPEkKeciu3HL2aF1BYOhyPq9gXV1dVGl0STxBuUUU7JOyLK/2e7myLde7aYoXsk122RTfKKG6fTiQcffNDgamgqGPKUU7kOMjMHZaxCqvXBBx9kuCuC3TVERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERArjXSiLXFdXF8LhsNFl5N3FixdRWloYu38h1ZpNPT09qKurM7qMgscj+SK2bt26ovzFn1AohL6+PoyOjhpdyoRGR0fR19eX8EfHVVdTU4N169YZXUbB42+8UlF55513sHjxYsyfPx/9/f2YNm2a0SWlNDY2huXLl+PUqVM4dOgQrr/+eqNLogLDkKei8eGHH+L222/H9OnTcejQIcyYMcPoktISCoWwePFifPrppzhy5Aiuvvpqo0uiAsLuGioKoVAIy5YtAwDs37+/YAIeAGbMmIH9+/cDAJYtW1aUXTc0eQx5Ut7Y2BhWr14Nv9+P/v7+gjwSvvrqq9Hf3w+/34/Vq1djbGzM6JKoQDDkSWnj4+NYu3Ytjh8/jv7+flRWVhpd0qRVVlaiv78fx48fx9q1azE+Pm50SVQAGPKkLCEENm3ahNdffx2vvvoqFixYYHRJU7ZgwQK8+uqreP3117Fp06aC+nFwMkbxXXxLRWP79u3o6OjA3r17cccddxhdTtbccccdcLlcWL16NWbOnIkdO3YYXRKZGEOelLRz5048+eSTePHFF2G1Wo0uJ+usViv+8Ic/YP369ZgzZw4eeugho0sik2LIk3I6OzuxZcsW7NixAw0NDUaXkzMNDQ14//33sWXLFsyaNQv19fVGl0QmxJAnpezbtw+NjY145JFH8MgjjxhdTs498sgjCAaDaGxsxMyZM3HPPfcYXRKZDL8MRco4evQoqqursXbtWrzwwguwWCxGl5QXQgg0NjZiz549OHjwIG677TajSyITYciTEk6ePInFixfjjjvuwN69e1FSUmJ0SXk1Pj6O1atX44033sChQ4eUuJKIsoMhTwXv7NmzWLRoEa6//nr09fXhy1/+stElGeL8+fNYsWIF3nnnHQwODmLu3LlGl0QmwJCngibvR3PFFVfgr3/9a0HdriAXQqEQ7rzzTly4cIH3uSEA/DIUFbCPP/4YmqYBAF577bWiD3jg0n1uXnvtNQCApmn4+OOPDa6IjMYjeSpI8ha8J0+exJEjRwr6dgW5MDIygttvvx0LFiwoiFsqU+7wSJ4Kzvj4OBoaGnD8+HEMDAww4BOorKzEwMAAjh8/joaGBt7npogx5KngbN68GW63G3v37uVVJCksWLAAe/fuhdvtxubNm40uhwzCL0NRQXE4HHA6ndi7dy+qq6uNLsf0qqur0d3djdWrV2PWrFlobm42uiTKMx7JU8Fob2/H448/jl27dil5P5pcsVqt2LVrFx5//HG0t7cbXQ7lGY/kqSB0dnZi06ZNeOKJJ7Bhwwajyyk4GzZswOjoKDZt2oQrr7yS97kpIgx5Mr0DBw6gsbERW7duxbZt24wup2Bt27YNo6OjaGxsREVFBZYuXWp0SZQHvISSTE3ej2bVqlXYvXt30dyPJleEEGhoaMDLL7/M+9wUCYY8mdbbb7+NxYsXY9GiRXjppZdQVlZmdElKCIfDWLNmDQYHB3Ho0CHceOONRpdEOcSQJ1OS96OZO3cuBgYGivZ+NLly/vx5LF26FO+99x7vc6M4hjyZzocffojFixejpKSE96PJIXmfm/HxcRw6dIj3uVEUL6EkUzl//jw0TcOFCxfQ19fHgM+hGTNmoK+vDxcuXICmaTh//rzRJVEOMOTJNMbGxrBy5UqcOXMG+/fvZxdCHsydOxf79+/HmTNnsHLlSoyNjRldEmUZQ55M4fPPP0djYyOOHTuGvr4+3o8mjyorK9HX14djx46hsbERn3/+udElURbxOnkyhU2bNqGnpwf9/f24+eabjS6n6Nx8883Yu3cvli9fjiuvvBLPPvus0SVRlvBIngzX0tICp9OJ7u5u3o/GQPI+N06nEy0tLUaXQ1nCI3kyVHt7OxwOB5599lmsWrXK6HKK3qpVq/D000/j5z//OWbNmoWmpiajS6IpYsiTYXp6erB582bs2LGDYWIiTU1NCIVC2Lx5M2bPno2amhqjS6Ip4HXyZIiDBw9i+fLl2LhxI55++mmjy6EENm/eDKfTif7+fnajFTD2yVPO/POf/8Snn34aN/zo0aNYtWoVampqsHPnTgMqo3Ts3LkTNTU1WLVqFY4ePRo3/pNPPsGxY8cMqIwywSN5yomRkRF885vfREVFBU6ePKl/m1L+9ujNN9+MV155hb89anLyuwt///vfo35L98MPP8SCBQvg9/tx+vRpXvJqYjySp5yQP07x0UcfoaqqCl6vF2fPnkV1dTWuu+46vPTSSwz4AjBt2jS89NJLuO6661BdXY2zZ8/C6/WiqqoKH330EQDwh0hMjkfylHWffvop5syZo3fVlJWVYebMmZg5cyYuv/xyHDx4ELNnzza4SsrE6Ogoqqur8dlnn+HcuXMIBoMIh8MAgOnTp+ODDz7A9OnTDa6SEuGRPGXd7t27ceHCBf1xOBzGuXPn4PV60dzczIAvQLNnz0ZzczPeffddnDt3Tg94ALhw4QJ2795tYHWUCo/kKauEEPjWt76FkZERxO5aJSUlKCsr079ZSYWjv78fq1evRjgcxvj4eNQ4i8WCyspKDA8P80ddTIhH8pRVBw4cwOnTp+MCHgDGx8cxNjYGTdPQ1dVlQHU0GV1dXdA0DWNjY3EBD1x6Yz99+jQOHDhgQHU0ER7JU1ZpmoY//elPuHjx4oTTfvDBB/ja176Wh6poss6ePYuvf/3rE05XWlqKZcuWwe1256EqygSP5ClrRkZGsG/fvpQBX1JSgtmzZ2PXrl0M+AIwd+5ctLe3Y/bs2SgpKUk63cWLF7Fv3z6MjIzksTpKB0Oesua5555DaWniO2WUlZVh+vTpeOyxx+D1evGzn/0sz9XRZNlsNni9Xjz22GOYPn160t/aLS0txXPPPZfn6mgi7K6hrIi9bFKSgfDQQw9h27ZtvLKmwI2OjuK3v/2t/k3lyKtsAF5OaUY8kqes6OzsjLpssqysDBaLBbW1tRgZGUFraysDXgGzZ89Ga2srRkZGUFtbC4vFEnVkf+HCBXR2dhpYIcXikTxNWeRlkyUlJbh48SJWrFiB3/3ud7jpppuMLo9y6K233sLDDz+Mvr4+lJaWYnx8nJdTmowSIf/ee+/B4/EYXUbR+tvf/obf//73AC79lNz999+Pb3/72wZXlR0lJSWwWq1JzzVM1cWLF9Hb25vw0sRC8u9//xt//OMf9ROvv/71r3HLLbcYXFXxqaqqir8aSijggQceEAD4x7+c/L388ss523dffvllw58f/9T5e+CBB+L2MSV+NOSzzz5DXV0d+wIp6ywWC86fP5+z5ctli8L/QE0Gq6+vx2effRY3nCdeiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ14BgUAA3d3dsFqtRpdCOZavbT3V9ai6TxZiuyhxP3lVhEIh/Otf/8LJkyfhdrvR29ub1nyPPvoodu3aNaV1ezwe7Nu3Dy0tLQAAu92ONWvWYM6cOaioqDDsfucTtUmqn5hrbW3F/Pnzcdddd2HGjBm5LjUvsrGt87GeXNSZbFvnc980Y7tMRImf/6uvrweAgv/REIfDAQB60GayaeQLYDKb0+FwYHR0FFu3bsX8+fMBXDriOHr0qH7EYdRukk6bBAIBVFRUAACCwaAe6CdOnNDnf/7551FeXp7x+i0WCzo7O1FXVzep+ifS1dWF+vr6vG3rTEx1PbmoM9m2zicztguQPAfZXWMizc3NaG5uzus6HQ4HTpw4gfb2dj3gAaC8vByapmFwcDCv9cRKp00iwzvyRb9w4UI8//zzAIANGzYgFArlpkjKm2TbmpIr6pAPhULo7u6GxWKBxWJBR0dHWtMEAgF9fGwfm9vthsVigdVqhc/ng8fj0eeVf1JbW5s+zOfzTapuq9WKU6dOxU3jcDj0o9hkPB4PWlpasH379qTTVFVVpVy/WdokmfLycmzZsgVutxuHDx+e8vLMKBQKoaOjQ283h8Ohb49k26KpqUlvX7ktI4dFCgQC+nZJNk06+2SqOoH09tlMqNIuU5azXyjOo7q6OlFXV5fxfJqmCbvdrj+22WxRj+U0TqdTCCGE3+8XmqYJTdNEMBjUx+P/f0R3cHBQCCGE1+sVAITNZhNCCDEwMCAAxC1bCCHsdrsYGhqKGiaXl6pum82m1+ByueLmsdvtCdcXu24Awu/3p5wu0frN1iapxgeDwah1ZwKA6OzszHi+dHV2dqZ8XonEPlebzaZvx9h2jtwWsk0HBwf1aZJtn8j1yGnktk60z6SzT6aqU4j09tlEzz8ZVdolXclysGhDXjZ25EYZHBwUmqbpj2UQxU4DQLhcLn1Yop0uUegC0De2EJfCJ9FOnWon7u3tFQDE8PBw1HLS3fHTXU8yZmyTbIxPNZ/ZQ95utycMoWSP0x2WaJrh4WEBQH+TFyL9fXKiOtOV7nzF1i4M+RjynTcV+Q4bSW6kyDeDdHaMoaGhuCAcGBiIO2JNtrxUNU00TzKTmceMbZKN8anmM3vIS16vV7S2tuY0zBINz3SfTFZnujKdr1jahSEfI52GTHdjpruzyG4NKdlH01S1pVtTOuROGHkkPREztslE4+WbUDpdAYmWWwgh73Q6haZp+hFlPsMsk30yVZ3pymS+YmqXZDlYtCdeNU0DcOkyu4mmSXQSxGazZbzOuro6uN1ueDwe+Hw+3HrrrRkvI5tWrFgBAHj33XfTnqcQ2+T48eMAgCVLlmR92WbQ3d2NjRs34plnnom6QiqXJrOt81VnU1NTXtcXyYztUvQhv2vXLv3SOp/Pp+8gAPRro8+cOaMPk9PW1NRkvM7q6moAwIsvvogjR47grrvuyngZTqcTQOo3p3RpmgZN01J+OcPn86GtrU1/bMY2SSUQCOCpp56Cpmn6ulRTW1sLAJg3b17O1yX3u7vvvlsflu4+mY86PR6PXhvb5f9l/JnAhCbTXRN5Rlz+2Wy2uJMksjtBnmh0uVxRJ0n8fr8+v+z2iDy5Enu2XZ5sbG1tTVhX5LyJulHk2XdN04TX6xVCfHEyVD4HuZ50uidkO8Q+d7muyOdu1jZJNn5oaCiu1kzBZN01kW0rn5Pcj71eb9THfb/fn3BbJFpGquUODAzo02iaFred0t0nU9UpRHr7bGSdseQFAPKcjirtki72ySfg9/v1gLHb7XEhJ6dxOp16w7tcrqggiXyTkDteomGSPNmYaF2x8yXbmb1er96fbrPZ9J3M5XJl9IKRgsGg6O3t1Zcpd0yn06nvnGZtk2Tj5ZuGvMxtsswW8onaQbaf3W7X92mbzaaHTDrbIln7DgwM6CFks9n0YIuVzj6Zqk4hJt5nU23ryD+5L6rSLulKloO8rQFRCma8rQFRIrytARFREWLIExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhjwRkcIY8kRECis1uoBs6enpwcqVK40ug2hSenp6jC6BClxPTw9qamrihisR8tdeey3C4TDWrl1rdCmkoMrKypwvm/suZcO1114bN0yJ33il9PE3RYmKC/vkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUVmp0AZRbAwMDeOedd/THx44dAwA4nc6o6ZYtW4Z58+bltTYiyj2LEEIYXQTljsViAQCUlZUBAIQQEELgssu++BAXDofx8MMP48knnzSkRiLKHXbXKK6xsRFlZWUIh8MIh8O4ePEixsfH9cfhcBgAsGTJEoMrJaJcYMgrrra2Vg/yZK666iosXbo0TxURUT4x5BW3ZMkSzJo1K+n4srIyrFu3DqWlPD1DpCKGvOJKSkpw3333Ydq0aQnHh8Nh1NXV5bkqIsoXnngtAseOHcNtt92WcNw111yDs2fP6idoiUgtPJIvArfccgvmzp0bN7ysrAz3338/A55IYQz5ImCxWLB+/Xr9MkopHA5j3bp1BlVFRPnA7poi8fbbb+Omm26KGlZZWYnTp08bVBER5QOP5IvEjTfeiBtuuEF/XFZWhp/+9KfGFUREecGQLyL333+/3mVz8eJF1NbWGlwREeUau2uKiNfrxbXXXgshBL73ve/hzTffNLokIsoxHskXkW984xtYuHAhAGD9+vUGV0NE+WD6I/kvfelLGBsbM7oMopR+85vfoKWlxegyiOKY/rvsY2NjWLlyJb+VmSXj4+MIBAKYM2eO0aUoo76+Hv/5z3+MLoMoIdOHPADU1NSgpqbG6DKIEnrllVeMLoEoKfbJExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhjwRkcIY8kRECmPIExEpjCFPRKQwhryJBQIBdHd3w2q1Gl0KERUohnwehEIheDwedHR0ZBTYjz76KGpra+F2u/O2zlQ8Hg8cDgcsFgssFgscDgdOnDiBQCAAi8WSlXVMxkTPVdab6K+trQ1utxuhUMiAyolyryB+NKTQtba2AkDGPw/X3t6OXbt25XWdyTgcDoyOjmLr1q1obm4GcOmTxtGjR/Hd7343K+uYrImeqxACgUAAFRUVAIBgMIgZM2YAAE6cOAGHw4GOjg48//zzKC8vz0/RRHli+t94tVgs6OzsVOLn/+TRbiZNPpl5sjk/AP2Ivbe3N+F4j8eDRYsWTWkd2TDRc002PhAIYMOGDQCA3bt3628A6aqvrwcAdHZ2ZjQfUT4o2V0TCoXQ3d2tfyTv6OhIa5pAIKCPj+0Pd7vdsFgssFqt8Pl88Hg8cR/9pba2Nn2Yz+ebVN1WqxWnTp2aQitMzOFwwOFwpJzG4/GgpaUF27dvTzpNVVVV3DAztm8y5eXl2LJlC9xuNw4fPjzl5RGZiZIh39DQgLfeegtCCAgh8Oabb8aFWUNDAz755BMIIeD3++F2u7Fhwwa9b3bDhg16f7jH44GmafB6vXC73dixYweqqqowMDAAALDb7VFHh7/85S9ht9sxNDSEefPmZVT3X/7yFwSDQfT29uLNN9/MQmtMzb59+wAA1113XcrpYo+Ozdi+qXz/+98HAPT19WVleUSmIUwOgOjs7Ex7epfLJQAIv9+vDxscHBSapumPBwYGEk4DQLhcrqh1xzZR7DC73S4AiGAwqA8LBoPCbrcnfC7Jmry3t1cAEMPDw1HLSTVPOoyY34ztm43xydTV1Ym6urqM5yPKB+WO5Lu6ugAg6gRaVVVVVH9yT09P3DQ33HBD1PzpWrNmDQCgv79fH3b8+HF9eLrkEeT8+fP1YZn2DZuFGduXqFgpF/LpXG6Y6IoVGaiZXq64cOFCaJoWFV5//vOfsXDhwoyWM9mraHLNZrMBQEaXGJqxfScin5/dbs/qcomMplzIa5oG4NKlcRNNE3kiUJKhlom6ujq9b9nn8+HWW2/NeBlmtWLFCgDAu+++m/Y8hdi+x48fBwAsWbIk68smMpKyIb9r1y796Mzn86GpqUmfRl6OeebMGX2YnLampibjdVZXVwMAXnzxRRw5cgR33XVXxstwOp0AUr85GUHTNGialvKThs/nQ1tbm/7YjO2bSiAQwFNPPQVN0/R1ESnD6JMCE0GGJ179fr/QNE0/iQZA2Gy2uBOamqYJTdP0k4Mul0vYbLao5cj55Um/yBOhkScVhfjiBGFra2vCuiLnjTyJKHm9XgFAaJomvF6vEOKLE5jyOWRqonXa7faEJzBjyTaNbUdZd2Q7yvWarX2TjR8aGoqrNVM88UpmplzIC3EpQGQo2O32uGCS0zidTv2F73K5ol78kW8S8r0w0TBpaGgo7uqYZMtKNL8QlwLTZrPpoS7D1eVyZRxA6awz3ZAX4lJI9vb26vXJNySn06m/KUUyU/smGy/fNAYHB9Nqg2QY8mRm/MYr0RTxG69kZsr1yRMR0RcY8kRECuNdKAtIurfzNXkPHBHlEUO+gDC8iShT7K4hIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlJYQfwyFJHZPfDAA3jhhReMLoMojulvNXzkyBGcPXvW6DKU8cYbb2Dnzp3Ys2eP0aUopaqqyugSiBIyfcgvWrTI6BKUEg6HAQA1NTUGV0JE+cA+eSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGEMeSIihTHkiYgUxpAnIlIYQ56ISGGlRhdAuTU2Nob//e9/+mP5/3PnzkVNd9VVV+W1LiLKD4sQQhhdBOWOxWJJa7rm5mbY7fYcV0NE+cbuGsXddNNNaU1XXl6e40qIyAgMecX94he/QElJScppSktLsWbNmjxVRET5xJBX3OrVq3HZZck3c0lJCX74wx/iq1/9ah6rIqJ8YcgrbubMmVi+fDlKSxOfYxdC4L777stzVUSULwz5ItDQ0IDx8fGE46ZNm4Z77703zxURUb4w5IvAPffcg8svvzxueFlZGVauXImvfOUrBlRFRPnAkC8CV1xxBX784x+jrKwsang4HEZ9fb1BVRFRPjDki0R9fT3C4XDUsCuvvBI/+tGPDKqIiPKBIV8klnROYOYAAAcJSURBVC5dGvWt1rKyMvzkJz/BtGnTDKyKiHKNIV8kSktLsW7dOr3Lhl01RMWBtzUoIm+88QbuvPNOAEBFRQXef//9lNfQE1Hh4yu8iPzgBz/ANddcA+BSHz0Dnkh9cd+Q+e9//4utW7cmva6aCpsM9n/84x9Yu3atwdVQLlRWVuKJJ54wugwyibjumq6uLtTX16OmpsaomiiHLly4gNOnT+M73/mO0aVQDvT09AC49E1mIiDF/eT37NmTzzqIKAvkQRqRxE5ZIiKFMeSJiBTGkCciUhhDnohIYQx5IiKFMeSJiBTGkCciUhhDnohIYQx5IiKFMeSJiBTGkCciUhhDnohIYQx5IiKFMeSJiBRWsCEfCATQ3d0Nq9VqdCmmU4htU4g1ExWCgg35DRs2oLa2Fm632+hSciYUCsHj8aCjoyOj8Hv00UczbhuLxRL15/F4kk7r8Xjipp+qyWxPj8cDh8Oh1+BwOHDixAkEAoGs1DRZE2232LaL/Gtra4Pb7UYoFDKgclKSiNHZ2SkSDDYlAAVT62TY7XZht9sn9TwnM4/X69Xns9lsSaez2Wz6dH6/P6N1pJJJzXa7XdhsNjE8PKwP8/v9ore31/D9Ip3t5vf79fHBYFAfPjQ0JDRNE5qmTaptC+n1S/nBkC8A+Qp5OV9ra6sAILxeb9x4r9erj89226e7TLvdLjRNSzp+cHDQFPvFRM8n2Xi/368HfeQbQDoK6fVL+THl7prYvlS32w2LxYKmpib4fD4AQHd3d9ww4NLH2o6OjqiP24FAIGr5bW1tsFgs6OjomPBj+MGDB6fUhRAKhfRa5TrTmSay5mTtYbVa4fP5UnZ1yOdqsVii2imTuq1WK06dOhU3jcPhgMPhSGt5S5cuBQAcOXIkbtyRI0f08YnqyPX29Hg8aGlpwfbt25POV1VVlbA2s223ZMrLy7Flyxa43W4cPnx4ysujIheb+pkeCWiaph+RDA0NCSG+OJKy2WxicHBQCPFFV0BkN4D82O/3+xOOb21t1Y8mg8Gg/hFYQsyRkNfrFU6nc9JdCJqmCbvdHlVf5GM5jdPpFEIkPuKKbI9kz31gYEAAiFu2EJeOUmU7Jnueieq22Wx6DS6XK24e2YUwETmP3Dax5HNIVFM+tqecJ9NtbMbtlmp8MBicsNssER7JU6ysdNck2lnTGSb7VZONj30xy37MRNMPDQ0Jl8uVUd2RZDBGrm9wcDCqW0C+yGOnARC17nSfO2L6Y2XwxUoVBrIPOrJvWgbEZF7sch75XGXgCXGpjQcGBpLWlI/tOZnnZcbtlo3xiTDkKZahIS8l6+eVR4Yulyth32TkkVemRzyx5JFcKomObmWgRr4ZpPPch4aG4kJmYGAg7mgw2fJS1TTRPKnEhm5ku0YGWarl53J7TuZ5mXG7ZWN8Igx5imV4yDudTqFpmhgeHo4bPzw8HPUxurW1NeHy5FF45FFnptJ5QSWbJtERazrPXXYZSMm6U1LVlm5N6YqcR7ar1+sVfr9/wqNeIXK/PWVgZ3JC0ozbbaLx8k0onS62SAx5imVoyEeGSLJ5hLh09CRf3JHBEDn9ZPtqJRk+iY7IYqeJXUfsEW+67REZZl6vV/T29iZcr1EhL/ukXS6XcLlcUVfbpHo+udyesnsq1XaKZcbtNtF42cUku8fSxZCnWIaGfDqPY68hTjZ9MBjUT0BOhtPp1F/0cp1erzdqeYmOMOURV+SLMd32kH3SNpstaRdGsnlj6870pF8ysfPIsE121J1qWK6250TbWXYXSWbcbqnGR54YzhRDnmJNOeQTfakjcpg8eko0TB5heb3eqI/3crz8uCqPDCNfvInWK4885VUUmZAvLLlM+SKOPaEZ+0UVl8sVFTiJ6oo8ERp7NJksRCPXGbu8SPI5a5qmt5M8Cow8Uk3n6hpZe2SNMogj30QSbUsh8rc95baK3T5yntgvEplxuyUbzy9DUbZNOeQjQ1HOl+4wGSB2u134/X796ozIj/t+v18/iZfoo33k8iLDbTI7uqxB1hQbIHIaefQMxJ9ETPe5S7INEq0rdr5kz0t+4pChLkPQ5XLpQTFRyKdaT6IuDaO3ZzAYFL29vVHfvpWXSSb6EpeZtluy8bJNpnJuiSFPsSxCCIEIXV1dqK+vR8xgIioAfP1SrIK9QRkREU2MIU9EpLBSowvIpXTvX8OPtkSkKqVDnuFNRMWO3TVERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApjyBMRKYwhT0SkMIY8EZHCGPJERApLehfKtWvX5rMOIsqCnp4eo0sgk4kL+erqaqxbtw7j4+NG1ENEU1BTU4PKykqjyyATifuNVyIiUgf75ImIFMaQJyJSGEOeiEhhDHkiIoX9HzXBoLU3XY0qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.99044636e-02, 6.77621886e-02, 2.03535259e-01, 4.91269566e-02,\n",
       "         8.40160102e-02, 1.43813431e-01, 1.26641616e-01, 9.62654501e-02,\n",
       "         6.44520968e-02, 1.04482584e-01],\n",
       "        [2.69218236e-02, 5.07885702e-02, 2.25267619e-01, 3.89914028e-02,\n",
       "         9.72983763e-02, 2.37147197e-01, 1.08519480e-01, 3.61363329e-02,\n",
       "         1.07288450e-01, 7.16407746e-02],\n",
       "        [5.74921183e-02, 4.42667417e-02, 2.42915615e-01, 5.41601777e-02,\n",
       "         1.09075740e-01, 1.74762219e-01, 1.30881682e-01, 5.53620160e-02,\n",
       "         5.03116660e-02, 8.07720423e-02],\n",
       "        [3.17528881e-02, 6.15120158e-02, 3.08201253e-01, 3.83319110e-02,\n",
       "         8.27065408e-02, 1.83121040e-01, 9.08005163e-02, 6.22726716e-02,\n",
       "         8.22003782e-02, 5.91007285e-02],\n",
       "        [4.57355268e-02, 3.62070575e-02, 2.46231586e-01, 5.68595454e-02,\n",
       "         1.18033215e-01, 1.62055284e-01, 1.30843982e-01, 6.12905882e-02,\n",
       "         6.28749654e-02, 7.98681527e-02],\n",
       "        [3.77154686e-02, 4.96413447e-02, 3.44123542e-01, 2.27096565e-02,\n",
       "         7.51068890e-02, 2.22017452e-01, 8.69101360e-02, 4.47618105e-02,\n",
       "         4.81163673e-02, 6.88973665e-02],\n",
       "        [4.07602228e-02, 4.89627458e-02, 3.76527488e-01, 3.59407552e-02,\n",
       "         6.95827678e-02, 1.53634697e-01, 1.22326933e-01, 4.57148217e-02,\n",
       "         5.37358262e-02, 5.28137535e-02],\n",
       "        [5.64434504e-06, 1.55319212e-05, 3.05555433e-01, 2.09877845e-02,\n",
       "         1.17129798e-03, 1.66018854e-03, 6.69764102e-01, 2.27650798e-06,\n",
       "         8.22270522e-04, 1.53701312e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radi i sa CategoricalCrossentropy-em\n",
    "model_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_2 = model_2.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.0437065e-02, 9.3152300e-02, 1.9991493e-01, 3.3336796e-02,\n",
       "         1.1651115e-01, 1.5550549e-01, 7.5138099e-02, 9.2423357e-02,\n",
       "         6.4718790e-02, 1.3886200e-01],\n",
       "        [7.3407762e-02, 4.2305011e-02, 3.0511001e-01, 2.4086498e-02,\n",
       "         6.7663863e-02, 2.1770722e-01, 1.1867033e-01, 5.0350450e-02,\n",
       "         4.4523407e-02, 5.6175549e-02],\n",
       "        [5.7775211e-02, 6.1386511e-02, 2.0760731e-01, 5.1982887e-02,\n",
       "         8.6937398e-02, 1.7861246e-01, 1.5880600e-01, 6.9986157e-02,\n",
       "         4.8501607e-02, 7.8404441e-02],\n",
       "        [3.8907576e-02, 7.3765442e-02, 3.3289137e-01, 4.0409740e-02,\n",
       "         5.2061200e-02, 1.7861071e-01, 8.8254154e-02, 7.2551541e-02,\n",
       "         5.7082858e-02, 6.5465450e-02],\n",
       "        [7.6598935e-06, 2.0072051e-05, 2.7863288e-01, 2.4626156e-02,\n",
       "         9.2124223e-04, 1.6309456e-03, 6.9287336e-01, 4.2152310e-06,\n",
       "         1.2652599e-03, 1.8243492e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00]],\n",
       "\n",
       "       [[5.1319882e-02, 5.9089568e-02, 2.3531978e-01, 5.3106803e-02,\n",
       "         1.1770908e-01, 1.6806023e-01, 8.2370460e-02, 7.0799947e-02,\n",
       "         7.3004521e-02, 8.9219749e-02],\n",
       "        [7.1090721e-02, 6.8704009e-02, 3.2957873e-01, 3.9277241e-02,\n",
       "         5.9691422e-02, 1.5853912e-01, 7.6843932e-02, 7.7812120e-02,\n",
       "         6.2760316e-02, 5.5702392e-02],\n",
       "        [4.6458840e-02, 5.7366617e-02, 3.1094798e-01, 5.5950426e-02,\n",
       "         9.4999447e-02, 1.5162581e-01, 7.1743622e-02, 5.5766419e-02,\n",
       "         1.0721320e-01, 4.7927611e-02],\n",
       "        [4.4671692e-02, 6.2887244e-02, 3.1893790e-01, 3.2206796e-02,\n",
       "         8.3464466e-02, 1.9477376e-01, 1.0874599e-01, 4.1737080e-02,\n",
       "         6.5507628e-02, 4.7067393e-02],\n",
       "        [6.3981399e-02, 5.2860286e-02, 2.3444156e-01, 4.8197445e-02,\n",
       "         1.1927745e-01, 1.4814244e-01, 1.0956206e-01, 5.9565131e-02,\n",
       "         9.6413091e-02, 6.7559116e-02],\n",
       "        [4.8420256e-06, 1.1396904e-05, 2.6810673e-01, 2.4586096e-02,\n",
       "         1.2191922e-03, 1.2119741e-03, 7.0424366e-01, 5.8069627e-06,\n",
       "         5.8037433e-04, 2.9975023e-05],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 343ms/step - loss: 0.4980"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4979720711708069"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3, 6, 1, 4, 1]), array([4, 9, 6, 3, 1, 3])]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pred_2[0,:5]\n",
    "p2 = pred_2[1,:6]\n",
    "\n",
    "y1_oh = tf.keras.utils.to_categorical(y[0], num_classes=10)\n",
    "y2_oh = tf.keras.utils.to_categorical(y[1], num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4979720592498779"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((-np.sum(y1_oh * np.log(p1))/40) + (-np.sum(y2_oh * np.log(p2))/40))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6856717109680176\n"
     ]
    }
   ],
   "source": [
    "oh_y_8= tf.keras.utils.to_categorical(y_test[:,:8], num_classes=10)\n",
    "print(-np.sum(oh_y_8 * np.log(pred_2[:,:8]))/40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 326ms/sample - loss: 2.4075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4074604511260986"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(X_test[:,:8],oh_y_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.05990446, 0.06776219, 0.20353526, 0.04912696, 0.08401601,\n",
       "         0.14381343, 0.12664162, 0.09626545, 0.0644521 , 0.10448258],\n",
       "        [0.02692182, 0.05078857, 0.22526762, 0.0389914 , 0.09729838,\n",
       "         0.2371472 , 0.10851948, 0.03613633, 0.10728845, 0.07164077],\n",
       "        [0.05749212, 0.04426674, 0.24291562, 0.05416018, 0.10907574,\n",
       "         0.17476222, 0.13088168, 0.05536202, 0.05031167, 0.08077204],\n",
       "        [0.03175289, 0.06151202, 0.30820125, 0.03833191, 0.08270654,\n",
       "         0.18312104, 0.09080052, 0.06227267, 0.08220038, 0.05910073],\n",
       "        [0.04573553, 0.03620706, 0.24623159, 0.05685955, 0.11803322,\n",
       "         0.16205528, 0.13084398, 0.06129059, 0.06287497, 0.07986815],\n",
       "        [0.03771547, 0.04964134, 0.34412354, 0.02270966, 0.07510689,\n",
       "         0.22201745, 0.08691014, 0.04476181, 0.04811637, 0.06889737],\n",
       "        [0.04076022, 0.04896275, 0.3765275 , 0.03594076, 0.06958277,\n",
       "         0.1536347 , 0.12232693, 0.04571482, 0.05373583, 0.05281375],\n",
       "        [0.03839651, 0.05472557, 0.10751758, 0.04085652, 0.15572351,\n",
       "         0.18172683, 0.0743579 , 0.14332241, 0.08138382, 0.12198933]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.predict(X_test[:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A19F304F48> None\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A19F304F48> None\n",
      "1\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A19F548708> None\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A19F548708> None\n",
      "2\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A181CC2588> None\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A181CC2588> None\n",
      "3\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x000001A19F548548> None\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x000001A19F548548> None\n",
      "4\n",
      "<__main__.MaskConv1D object at 0x000001A19B02A788> None\n",
      "<__main__.MaskConv1D object at 0x000001A19B02A788> Tensor(\"lambda/Identity:0\", shape=(None, None), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "for num,layer in enumerate(model_2.layers):\n",
    "    print(num)\n",
    "    print(layer,layer.input_mask)\n",
    "    print(layer,layer.output_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = []\n",
    "for layer in model_2.layers:\n",
    "    model_outputs.append(layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.Model(inputs=model_2.input, outputs=model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv1d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer lambda is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 40, 2048), dtype=float64, numpy=\n",
       " array([[[ 0.82352942,  0.16078432,  0.78431374, ...,  0.99607843,\n",
       "           0.39215687,  0.01176471],\n",
       "         [ 0.8392157 ,  0.07450981,  0.70588237, ...,  0.71764708,\n",
       "           0.60784316,  0.36078432],\n",
       "         [ 0.69411767,  0.95294118,  0.67450982, ...,  0.65490198,\n",
       "           0.54901963,  0.67843139],\n",
       "         ...,\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ],\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ],\n",
       "         [10.        , 10.        , 10.        , ..., 10.        ,\n",
       "          10.        , 10.        ]]])>,\n",
       " <tf.Tensor: shape=(1, 40, 32), dtype=float32, numpy=\n",
       " array([[[ 1.2419618 ,  0.        ,  0.        , ...,  0.02798664,\n",
       "           0.3083924 ,  0.        ],\n",
       "         [ 0.7955876 ,  0.        ,  0.05573715, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 1.1923463 ,  0.        ,  0.03733695, ...,  0.        ,\n",
       "           0.7864176 ,  0.        ],\n",
       "         ...,\n",
       "         [24.745825  ,  0.        ,  0.        , ...,  0.        ,\n",
       "           5.12107   ,  0.        ],\n",
       "         [24.745825  ,  0.        ,  0.        , ...,  0.        ,\n",
       "           5.12107   ,  0.        ],\n",
       "         [20.473392  ,  0.        ,  3.4832222 , ...,  0.        ,\n",
       "           0.35066777,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       " array([[[5.99044524e-02, 6.77621737e-02, 2.03535259e-01, 4.91269454e-02,\n",
       "          8.40159953e-02, 1.43813416e-01, 1.26641601e-01, 9.62654427e-02,\n",
       "          6.44520894e-02, 1.04482569e-01],\n",
       "         [2.69218273e-02, 5.07885739e-02, 2.25267589e-01, 3.89914066e-02,\n",
       "          9.72983763e-02, 2.37147182e-01, 1.08519480e-01, 3.61363366e-02,\n",
       "          1.07288443e-01, 7.16407672e-02],\n",
       "         [5.74921183e-02, 4.42667417e-02, 2.42915615e-01, 5.41601777e-02,\n",
       "          1.09075740e-01, 1.74762249e-01, 1.30881682e-01, 5.53620160e-02,\n",
       "          5.03116660e-02, 8.07720423e-02],\n",
       "         [3.17528956e-02, 6.15120269e-02, 3.08201313e-01, 3.83319184e-02,\n",
       "          8.27065408e-02, 1.83121085e-01, 9.08005014e-02, 6.22726716e-02,\n",
       "          8.22003782e-02, 5.91007285e-02],\n",
       "         [4.57355343e-02, 3.62070575e-02, 2.46231586e-01, 5.68595529e-02,\n",
       "          1.18033223e-01, 1.62055284e-01, 1.30843982e-01, 6.12905882e-02,\n",
       "          6.28749728e-02, 7.98681527e-02],\n",
       "         [3.77154648e-02, 4.96413410e-02, 3.44123513e-01, 2.27096546e-02,\n",
       "          7.51068965e-02, 2.22017437e-01, 8.69101286e-02, 4.47618067e-02,\n",
       "          4.81163673e-02, 6.88973591e-02],\n",
       "         [4.07602228e-02, 4.89627458e-02, 3.76527488e-01, 3.59407552e-02,\n",
       "          6.95827678e-02, 1.53634697e-01, 1.22326933e-01, 4.57148105e-02,\n",
       "          5.37358262e-02, 5.28137535e-02],\n",
       "         [5.64434458e-06, 1.55319212e-05, 3.05555582e-01, 2.09877733e-02,\n",
       "          1.17129798e-03, 1.66018843e-03, 6.69764042e-01, 2.27650776e-06,\n",
       "          8.22269998e-04, 1.53701294e-05],\n",
       "         [4.03948533e-12, 2.12571571e-10, 9.99801219e-01, 1.40127141e-13,\n",
       "          3.32705849e-06, 1.95429588e-04, 6.51612364e-09, 1.10061932e-10,\n",
       "          1.44355117e-09, 3.44519058e-09],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [5.66419063e-14, 2.55143959e-14, 9.99456823e-01, 1.96589151e-18,\n",
       "          3.64647590e-10, 5.43221366e-04, 3.95372446e-09, 1.16665734e-15,\n",
       "          6.62872209e-13, 1.40184105e-14],\n",
       "         [7.11198211e-10, 6.13781470e-10, 4.57846344e-01, 1.15655109e-12,\n",
       "          3.11057966e-06, 5.42144418e-01, 1.47430470e-07, 5.01924706e-06,\n",
       "          6.28886667e-08, 9.12710391e-07]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 40), dtype=bool, numpy=\n",
       " array([[ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False]])>,\n",
       " <tf.Tensor: shape=(1, 40, 10), dtype=float32, numpy=\n",
       " array([[[5.9904452e-02, 6.7762174e-02, 2.0353526e-01, 4.9126945e-02,\n",
       "          8.4015995e-02, 1.4381342e-01, 1.2664160e-01, 9.6265443e-02,\n",
       "          6.4452089e-02, 1.0448257e-01],\n",
       "         [2.6921827e-02, 5.0788574e-02, 2.2526759e-01, 3.8991407e-02,\n",
       "          9.7298376e-02, 2.3714718e-01, 1.0851948e-01, 3.6136337e-02,\n",
       "          1.0728844e-01, 7.1640767e-02],\n",
       "         [5.7492118e-02, 4.4266742e-02, 2.4291562e-01, 5.4160178e-02,\n",
       "          1.0907574e-01, 1.7476225e-01, 1.3088168e-01, 5.5362016e-02,\n",
       "          5.0311666e-02, 8.0772042e-02],\n",
       "         [3.1752896e-02, 6.1512027e-02, 3.0820131e-01, 3.8331918e-02,\n",
       "          8.2706541e-02, 1.8312109e-01, 9.0800501e-02, 6.2272672e-02,\n",
       "          8.2200378e-02, 5.9100728e-02],\n",
       "         [4.5735534e-02, 3.6207058e-02, 2.4623159e-01, 5.6859553e-02,\n",
       "          1.1803322e-01, 1.6205528e-01, 1.3084398e-01, 6.1290588e-02,\n",
       "          6.2874973e-02, 7.9868153e-02],\n",
       "         [3.7715465e-02, 4.9641341e-02, 3.4412351e-01, 2.2709655e-02,\n",
       "          7.5106896e-02, 2.2201744e-01, 8.6910129e-02, 4.4761807e-02,\n",
       "          4.8116367e-02, 6.8897359e-02],\n",
       "         [4.0760223e-02, 4.8962746e-02, 3.7652749e-01, 3.5940755e-02,\n",
       "          6.9582768e-02, 1.5363470e-01, 1.2232693e-01, 4.5714810e-02,\n",
       "          5.3735826e-02, 5.2813753e-02],\n",
       "         [5.6443446e-06, 1.5531921e-05, 3.0555558e-01, 2.0987773e-02,\n",
       "          1.1712980e-03, 1.6601884e-03, 6.6976404e-01, 2.2765078e-06,\n",
       "          8.2227000e-04, 1.5370129e-05],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00],\n",
       "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "          0.0000000e+00, 0.0000000e+00]]], dtype=float32)>]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Još jedan novi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MASK_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    \n",
    "    mask = tf.keras.layers.Masking(mask_value=10.).compute_mask(ulaz)\n",
    "    \n",
    "    srednji_1 = tf.keras.layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(ulaz)\n",
    "    srednji_2 = tf.keras.layers.Conv1D(10, 1, activation=\"softmax\")(srednji_1)\n",
    "    \n",
    "    izlaz = MaskConv1D()(srednji_2, mask=mask)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = MASK_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 2048)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 32)     196640      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_NotEqual (TensorFlo [(None, None, 2048)] 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 10)     330         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Any (TensorFlowOpLa [(None, None)]       0           tf_op_layer_NotEqual[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mask_conv1d (MaskConv1D)        (None, None, 10)     0           conv1d_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 196,970\n",
      "Trainable params: 196,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:2545 _defun_call  *\n        return self._make_op(inputs)\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:2523 _make_op\n        c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: 2 errors while building NodeDef 'NotEqual' using Op<name=NotEqual; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, ..., DT_QINT8, DT_QINT32, DT_STRING, DT_BOOL, DT_COMPLEX128]; attr=incompatible_shape_error:bool,default=true; is_commutative=true>:\n    Inconsistent values for attr 'T' DT_DOUBLE vs. DT_FLOAT\n    Inconsistent values for attr 'T' DT_DOUBLE vs. DT_FLOAT\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-587-a3443cb32a2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_defun_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3209\u001b[0m     \u001b[1;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3210\u001b[0m     \u001b[1;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3211\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3212\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:2545 _defun_call  *\n        return self._make_op(inputs)\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:2523 _make_op\n        c_op = ops._create_c_op(graph, node_def, inputs, control_inputs=[])\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: 2 errors while building NodeDef 'NotEqual' using Op<name=NotEqual; signature=x:T, y:T -> z:bool; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, ..., DT_QINT8, DT_QINT32, DT_STRING, DT_BOOL, DT_COMPLEX128]; attr=incompatible_shape_error:bool,default=true; is_commutative=true>:\n    Inconsistent values for attr 'T' DT_DOUBLE vs. DT_FLOAT\n    Inconsistent values for attr 'T' DT_DOUBLE vs. DT_FLOAT\n"
     ]
    }
   ],
   "source": [
    "model_4(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A19EE32548> None\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001A19EE32548> None\n",
      "1\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A19EE32E08> None\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A19EE32E08> None\n",
      "2\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A1A079A6C8> None\n",
      "<tensorflow.python.keras.layers.convolutional.Conv1D object at 0x000001A1A079A6C8> None\n",
      "3\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x000001A19EB5A988> None\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x000001A19EB5A988> None\n",
      "4\n",
      "<__main__.MaskConv1D object at 0x000001A19E860388> None\n",
      "<__main__.MaskConv1D object at 0x000001A19E860388> Tensor(\"lambda/Identity:0\", shape=(None, None), dtype=bool)\n",
      "5\n",
      "<tensorflow.python.keras.layers.core.Masking object at 0x000001A19F368F48> Tensor(\"lambda/Identity:0\", shape=(None, None), dtype=bool)\n",
      "<tensorflow.python.keras.layers.core.Masking object at 0x000001A19F368F48> Tensor(\"masking/Identity_1:0\", shape=(None, None), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "for num,layer in enumerate(model_4.layers):\n",
    "    print(num)\n",
    "    print(layer,layer.input_mask)\n",
    "    print(layer,layer.output_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testiranje brzine izračuna modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generiran skup podataka sa 620 opažanja, veličine: 1646.93 MB\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = video_data_generator(620, min_len=182, max_len=454)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 454)\n"
     ]
    }
   ],
   "source": [
    "get_seq_lengths(X_train, only_min_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = build_dataset(X_train, y_train, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela sa LSTM slojem od 512 jedinica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_512_model = build_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_512_model.fit(test_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovo je sasvim ok vrijeme potrebno za učenje ove vrste modela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idemo provjeriti koliko bi trajalo učenje bez potpore GPU-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiranje modela koji ne podupire GPU\n",
    "def non_gpu_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    ulaz = tf.keras.Input(shape=(None, 2048))\n",
    "    mask = tf.keras.layers.Masking(mask_value=(10.), input_shape=(None, 2048))(ulaz)\n",
    "    srednji = tf.keras.layers.LSTM(512, activation=\"relu\", return_sequences=True)(mask)\n",
    "    izlaz = tf.keras.layers.Dense(10, activation=\"softmax\")(srednji)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=ulaz, outputs=izlaz)\n",
    "    \n",
    "    model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_model = non_gpu_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_model.fit(test_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Čim se ne držimo preporuka vezanih za preddefinirane postavke LSTM sloja, npr. kao aktivaciju umjesto `tanh` funkcije stavimo `relu`, učenje postaje oko **12,5x sporije.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela sa LSTM slojem od 1024 jedinica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1024_model = build_compiled_model(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1024_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broj parametara u ovom modelu je **2,4x** veći od prvog testnog modela,\n",
    "(12,5 milijuna parametara u odnosu na 5,3 milijuna)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1024_model.fit(test_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učenje je sporije cca **2,6x** u odnosu na prvi model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela sa biLSTM slojem od 512 jedinica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_512_model = build_compiled_model(512, bidirect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 2048)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 1024)        10489856  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 10)          10250     \n",
      "=================================================================\n",
      "Total params: 10,500,106\n",
      "Trainable params: 10,500,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bilstm_512_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 41s 267ms/step - loss: 1.8253\n",
      "Epoch 2/5\n",
      "135/155 [=========================>....] - ETA: 4s - loss: 1.8198"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 512, 1, 364, 4, 512] \n\t [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\n\t [[StatefulPartitionedCall_1]] [Op:__inference_distributed_function_31025]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-adc972d0b68f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbilstm_512_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 2048, 512, 1, 364, 4, 512] \n\t [[{{node gradients/cond_grad/If/then/_0/gradients/CudnnRNNV3_grad/CudnnRNNBackpropV3}}]]\n\t [[StatefulPartitionedCall_1]] [Op:__inference_distributed_function_31025]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "bilstm_512_model.fit(test_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nažalost ne možemo učiti dvosmjerni LSTM, potrebno ga je testirati na Colabu, vjerojatno ostajme bez GPU memorije prema jednom stackoverflow postu, dok drugi tvrde da to nema veze sa memorijom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela sa biLSTM slojem od 1024 jedinica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_1024_model = build_compiled_model(1024, bidirect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 2048)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 2048)        25174016  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 10)          20490     \n",
      "=================================================================\n",
      "Total params: 25,194,506\n",
      "Trainable params: 25,194,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bilstm_1024_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "155/155 [==============================] - 110s 707ms/step - loss: 1.8656\n",
      "Epoch 2/5\n",
      "155/155 [==============================] - 102s 656ms/step - loss: 1.8643\n",
      "Epoch 3/5\n",
      "112/155 [====================>.........] - ETA: 27s - loss: 1.8567"
     ]
    }
   ],
   "source": [
    "bilstm_1024_model.fit(test_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
