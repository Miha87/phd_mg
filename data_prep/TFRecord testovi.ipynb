{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom dokumentu biti će pokazano kako spremati podatke u TFRecord te ih iz njega pročitati.\n",
    "Glavni cilj je ispitati utjecaj različitih načina zapisivanja podataka u TFRecord formatu, te utjecaj na veličinu\n",
    "tako spremljenih podataka i brzinu čitanja sa diska."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Biblioteke, podatci i model za testiranje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1. Potrebne biblioteke za testiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uvoz potrebnih biblioteka za slijedeće korake\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Home direktorij u koji će biti pohranjeni rezultati eksperimenata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = os.chdir(\"C:/Users/Public/Testni_podatci/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Funkcija za podizanje skupa podataka za testiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader(dataset):\n",
    "    data = dataset.load_data()\n",
    "    #Koristimo samo trening podatke\n",
    "    X, y = data[0][0], data[0][1]\n",
    "    #Ispis dimenzija kreiranih podataka\n",
    "    print(\"Dimenzije X:\", X.shape,\"\\nDimenzije y:\", y.shape)\n",
    "    #Ispis tipa podatka za X i y\n",
    "    print(\"Tip objekta za X:\", X.dtype, \"\\nTip objekta za y:\", y.dtype)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenzije X: (60000, 28, 28) \n",
      "Dimenzije y: (60000,)\n",
      "Tip objekta za X: uint8 \n",
      "Tip objekta za y: uint8\n"
     ]
    }
   ],
   "source": [
    "#Podizanje potrebnih podataka\n",
    "from tensorflow.keras.datasets import mnist\n",
    "X, y = test_data_loader(mnist)\n",
    "#Uklanjanje nepotrebnih stvari\n",
    "del mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Funkcija za kreiranje kompajliranog modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compiled_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pomoćne funkcije potrebne za kreiranje, zapisivanje i čitanje TFRecorda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Funkcija za pretvaranje array-a u raw bajt string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za kreiranje bytova iz slika - one su stringovi kada bi ih čitali\n",
    "#kao jpeg sa diska - OPONAŠAMO OVAJ PROCES SA OVOM FUNKCIJOM\n",
    "def images_as_bytes(image):\n",
    "    '''Funkcija koja pretvara sliku u raw bajtove(string)'''\n",
    "    #Iz razloga što mnist slike nemaju dimenziju \"RGB\",\n",
    "    #a framework zahtjeva da slika ima 3 dimenzije\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "    #Ne radimo enkodiranje u jpeg, što znači da će ovo imati veću težinu (uint8)\n",
    "    #ali će biti brže čitanje\n",
    "    return image.tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Pomoćne funkcije za kreiranje Feature-a određenog tipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcije za stvaranje BytesList, Int64List, FloatList iz ulaznih vrijednosti\n",
    "#ovo je potrebno da bi naši podatci mogli biti ulaz za Feature\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Funkcija za kreiranje Example-a jednog opažanja u skupu podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za konverziju uzorka (slika + label) u Example\n",
    "def sample2example(image, label):\n",
    "    '''Radi pretvorbu slike i oznake u Example'''\n",
    "    #Kreiramo Feature dict\n",
    "    feature_dict = {\n",
    "        \"image\": _bytes_feature(images_as_bytes(image)),\n",
    "        \"label\": _int64_feature(label)\n",
    "    }\n",
    "    features = tf.train.Features(feature=feature_dict)\n",
    "    return tf.train.Example(features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Funkcija za serijalizaciju Example-a, i zapisivanje u TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecord_writer(filename, images, labels, use_compression=False):\n",
    "    '''Zapisivanje TF Recorda u ciljanu datoteku, uz bool izbor kompresije'''\n",
    "    \n",
    "    if use_compression:\n",
    "        options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "    else:\n",
    "        options = None\n",
    "    \n",
    "    num_samples = 0    \n",
    "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
    "        for image, label in zip(images, labels):\n",
    "            example = sample2example(image, label)\n",
    "            #Da bi mogli zapisati Example potrebno ga je serijalizirati\n",
    "            writer.write(example.SerializeToString())\n",
    "            num_samples += 1\n",
    "    print(\"Broj zapisanih uzoraka:\", num_samples)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj zapisanih uzoraka: 60000\n"
     ]
    }
   ],
   "source": [
    "#Test - bez kompresije\n",
    "filename = \"test.tfrecord\"\n",
    "tfrecord_writer(filename, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj zapisanih uzoraka: 60000\n"
     ]
    }
   ],
   "source": [
    "#Test - sa kompresijom\n",
    "filename = \"zip_test.tfrecord\"\n",
    "tfrecord_writer(filename, X, y, use_compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Funkcija za parsiranje zapisanog TFRecorda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example2sample(example):\n",
    "    #Obavezno definiramo opis značajki u Exampleu, ovo vraća dict sa image, labelom\n",
    "    feat_desc = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    #Za jedno opažanje\n",
    "    sample = tf.io.parse_example(example, feat_desc)\n",
    "    #Dekodiranje raw byte stringa u sliku koju možemo vizulizirati\n",
    "    sample['image'] = tf.io.decode_raw(sample['image'], tf.uint8)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': <tf.Tensor: shape=(784,), dtype=uint8, numpy=\n",
      "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
      "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
      "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
      "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
      "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
      "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
      "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
      "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
      "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
      "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
      "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
      "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
      "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0], dtype=uint8)>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=5>}]\n",
      "Da li parser vraća točnu kopiju slike: True\n"
     ]
    }
   ],
   "source": [
    "#Testiranje funkcije\n",
    "dataset = tf.data.TFRecordDataset(\"test.tfrecord\", compression_type=None)\n",
    "image = []\n",
    "for example in dataset.map(example2sample).take(1): image.append(example)\n",
    "print(image)\n",
    "print(\"Da li parser vraća točnu kopiju slike:\", (image[0]['image'].numpy().reshape((28, 28)) == X[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Funkcija za preprocesuiranje uzorka: tip podatka, normalizacija, reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    '''Radi predprocesuiranja, izlaz je tuple(image, sample)'''\n",
    "    \n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "    #U originalni oblik  - iz 1d u 3d tenzor\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: shape=(28, 28, 1), dtype=float32, numpy=\n",
      "array([[[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.01176471],\n",
      "        [0.07058824],\n",
      "        [0.07058824],\n",
      "        [0.07058824],\n",
      "        [0.49411765],\n",
      "        [0.53333336],\n",
      "        [0.6862745 ],\n",
      "        [0.10196079],\n",
      "        [0.6509804 ],\n",
      "        [1.        ],\n",
      "        [0.96862745],\n",
      "        [0.49803922],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.11764706],\n",
      "        [0.14117648],\n",
      "        [0.36862746],\n",
      "        [0.6039216 ],\n",
      "        [0.6666667 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.88235295],\n",
      "        [0.6745098 ],\n",
      "        [0.99215686],\n",
      "        [0.9490196 ],\n",
      "        [0.7647059 ],\n",
      "        [0.2509804 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.19215687],\n",
      "        [0.93333334],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.9843137 ],\n",
      "        [0.3647059 ],\n",
      "        [0.32156864],\n",
      "        [0.32156864],\n",
      "        [0.21960784],\n",
      "        [0.15294118],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.07058824],\n",
      "        [0.85882354],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.7764706 ],\n",
      "        [0.7137255 ],\n",
      "        [0.96862745],\n",
      "        [0.94509804],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.3137255 ],\n",
      "        [0.6117647 ],\n",
      "        [0.41960785],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.8039216 ],\n",
      "        [0.04313726],\n",
      "        [0.        ],\n",
      "        [0.16862746],\n",
      "        [0.6039216 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.05490196],\n",
      "        [0.00392157],\n",
      "        [0.6039216 ],\n",
      "        [0.99215686],\n",
      "        [0.3529412 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.54509807],\n",
      "        [0.99215686],\n",
      "        [0.74509805],\n",
      "        [0.00784314],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.04313726],\n",
      "        [0.74509805],\n",
      "        [0.99215686],\n",
      "        [0.27450982],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.13725491],\n",
      "        [0.94509804],\n",
      "        [0.88235295],\n",
      "        [0.627451  ],\n",
      "        [0.42352942],\n",
      "        [0.00392157],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.31764707],\n",
      "        [0.9411765 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.46666667],\n",
      "        [0.09803922],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.1764706 ],\n",
      "        [0.7294118 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.5882353 ],\n",
      "        [0.10588235],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.0627451 ],\n",
      "        [0.3647059 ],\n",
      "        [0.9882353 ],\n",
      "        [0.99215686],\n",
      "        [0.73333335],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.9764706 ],\n",
      "        [0.99215686],\n",
      "        [0.9764706 ],\n",
      "        [0.2509804 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.18039216],\n",
      "        [0.50980395],\n",
      "        [0.7176471 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.8117647 ],\n",
      "        [0.00784314],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.15294118],\n",
      "        [0.5803922 ],\n",
      "        [0.8980392 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.98039216],\n",
      "        [0.7137255 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.09411765],\n",
      "        [0.44705883],\n",
      "        [0.8666667 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.7882353 ],\n",
      "        [0.30588236],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.09019608],\n",
      "        [0.25882354],\n",
      "        [0.8352941 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.7764706 ],\n",
      "        [0.31764707],\n",
      "        [0.00784314],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.07058824],\n",
      "        [0.67058825],\n",
      "        [0.85882354],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.7647059 ],\n",
      "        [0.3137255 ],\n",
      "        [0.03529412],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.21568628],\n",
      "        [0.6745098 ],\n",
      "        [0.8862745 ],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.95686275],\n",
      "        [0.52156866],\n",
      "        [0.04313726],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.53333336],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.99215686],\n",
      "        [0.83137256],\n",
      "        [0.5294118 ],\n",
      "        [0.5176471 ],\n",
      "        [0.0627451 ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]],\n",
      "\n",
      "       [[0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ],\n",
      "        [0.        ]]], dtype=float32)>, <tf.Tensor: shape=(), dtype=int64, numpy=5>)]\n"
     ]
    }
   ],
   "source": [
    "#Testiranje funkcije\n",
    "dataset = tf.data.TFRecordDataset(\"test.tfrecord\")\n",
    "dataset = dataset.take(1)\n",
    "dataset = dataset.map(example2sample)\n",
    "dataset = dataset.map(preprocess)\n",
    "\n",
    "image = []\n",
    "for example in dataset: image.append(example)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracija: 1\n",
      "Iteracija: 2\n",
      "Iteracija: 3\n",
      "Iteracija: 4\n",
      "Iteracija: 5\n",
      "Iteracija: 6\n",
      "Iteracija: 7\n",
      "Iteracija: 8\n",
      "Iteracija: 9\n",
      "Iteracija: 10\n",
      "Iteracija: 11\n",
      "Iteracija: 12\n",
      "Iteracija: 13\n",
      "Iteracija: 14\n",
      "Iteracija: 15\n",
      "Iteracija: 16\n",
      "Iteracija: 17\n",
      "Iteracija: 18\n",
      "Iteracija: 19\n",
      "Iteracija: 20\n"
     ]
    }
   ],
   "source": [
    "#Test rada funkcije\n",
    "Iteracija = 1\n",
    "num_iters = 20\n",
    "for example in tf.data.TFRecordDataset(\"test.tfrecord\").batch(32):\n",
    "    print(\"Iteracija:\", Iteracija)\n",
    "    Iteracija += 1\n",
    "    num_iters -= 1\n",
    "    if num_iters == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Funkcija za testiranje ulaznog pipeline-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def pipeline_timer(dataset, num_iterations=20):\n",
    "    '''Mjeri izvođenja definiranog broja iteracije iz \n",
    "    zadanog dataset-a'''\n",
    "    \n",
    "    print(\"Početak mjerenja\")\n",
    "    start_time = timer()\n",
    "    process_times = []\n",
    "    for example in dataset:\n",
    "        end_time = timer()\n",
    "        process_times.append(end_time - start_time)\n",
    "        start_time = end_time\n",
    "        num_iterations -= 1\n",
    "        if num_iterations == 0:\n",
    "            break\n",
    "    print(\"Kraj mjerenja\")\n",
    "    print(\"Prosječno vrijeme po batchu:\", f\"{np.mean(process_times)} sekundi\")\n",
    "    return process_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.00037874199999350823 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02839980000135256,\n",
       " 0.00017490000027464703,\n",
       " 9.439999848837033e-05,\n",
       " 8.679999882588163e-05,\n",
       " 9.689999933470972e-05,\n",
       " 8.800000068731606e-05,\n",
       " 8.610000077169389e-05,\n",
       " 9.00999984878581e-05,\n",
       " 8.750000051804818e-05,\n",
       " 0.0002137000010407064,\n",
       " 0.00011780000204453245,\n",
       " 8.819999857223593e-05,\n",
       " 8.570000136387534e-05,\n",
       " 9.17999968805816e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.100000195554458e-05,\n",
       " 8.030000026337802e-05,\n",
       " 8.41999972180929e-05,\n",
       " 8.070000330917537e-05,\n",
       " 0.00017109999680542387,\n",
       " 9.950000094249845e-05,\n",
       " 8.22000001790002e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.059999890974723e-05,\n",
       " 8.069999967119657e-05,\n",
       " 8.05000017862767e-05,\n",
       " 8.099999831756577e-05,\n",
       " 8.330000127898529e-05,\n",
       " 0.00016870000035851263,\n",
       " 9.679999857326038e-05,\n",
       " 8.22000001790002e-05,\n",
       " 8.100000195554458e-05,\n",
       " 8.049999814829789e-05,\n",
       " 8.069999967119657e-05,\n",
       " 8.019999950192869e-05,\n",
       " 8.040000102482736e-05,\n",
       " 8.059999890974723e-05,\n",
       " 8.100000195554458e-05,\n",
       " 0.00023610000062035397,\n",
       " 0.00010289999772794545,\n",
       " 8.22000001790002e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.059999890974723e-05,\n",
       " 8.060000254772604e-05,\n",
       " 7.989999721758068e-05,\n",
       " 8.069999967119657e-05,\n",
       " 0.00016959999993559904,\n",
       " 9.820000195759349e-05,\n",
       " 8.309999975608662e-05,\n",
       " 8.140000136336312e-05,\n",
       " 8.179999713320285e-05,\n",
       " 8.030000026337802e-05,\n",
       " 8.000000161700882e-05,\n",
       " 8.030000026337802e-05,\n",
       " 9.569999747327529e-05,\n",
       " 8.060000254772604e-05,\n",
       " 0.0001640999980736524,\n",
       " 0.0001109000004362315,\n",
       " 8.720000187167898e-05,\n",
       " 8.209999941755086e-05,\n",
       " 8.130000060191378e-05,\n",
       " 8.069999967119657e-05,\n",
       " 8.039999738684855e-05,\n",
       " 8.02000031399075e-05,\n",
       " 7.999999797903001e-05,\n",
       " 8.069999967119657e-05,\n",
       " 0.0001666999996814411,\n",
       " 9.950000094249845e-05,\n",
       " 8.1900001532631e-05,\n",
       " 8.129999696393497e-05,\n",
       " 8.110000271699391e-05,\n",
       " 8.309999975608662e-05,\n",
       " 8.099999831756577e-05,\n",
       " 8.019999950192869e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.030000026337802e-05,\n",
       " 0.0002282999994349666,\n",
       " 0.00010100000145030208,\n",
       " 8.629999865661375e-05,\n",
       " 8.130000060191378e-05,\n",
       " 8.010000237845816e-05,\n",
       " 8.099999831756577e-05,\n",
       " 8.019999950192869e-05,\n",
       " 8.000000161700882e-05,\n",
       " 8.049999814829789e-05,\n",
       " 0.00016370000230381265,\n",
       " 9.759999738889746e-05,\n",
       " 8.410000009462237e-05,\n",
       " 8.08000004326459e-05,\n",
       " 8.349999916390516e-05,\n",
       " 8.060000254772604e-05,\n",
       " 8.129999696393497e-05,\n",
       " 8.08000004326459e-05,\n",
       " 7.980000009411015e-05,\n",
       " 8.010000237845816e-05,\n",
       " 0.00016349999714293517,\n",
       " 9.660000068834051e-05,\n",
       " 8.270000034826808e-05]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test funkcije za mjerenje vremena\n",
    "dataset = tf.data.TFRecordDataset(\"test.tfrecord\").batch(32)\n",
    "pipeline_timer(dataset, num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot za usporedbu vremena različitih pristupa\n",
    "def box_graph(data_list, name_list):\n",
    "    '''Iscrtava boxplot za podatke iz data_list-e,\n",
    "    daje imena svakog grupi prema name_list-u'''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Usporedba vremena za grupe u sekundama')\n",
    "    bp = ax.boxplot(data_list)\n",
    "    plt.xticks(list(range(1, len(name_list)+1)), name_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Eksperimenti sa ulaznim pipelineom baziranim na TFRecordu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za definiranje testnog neoptimizranog pipeline-a\n",
    "def base_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija)\n",
    "    dataset = dataset.map(example2sample)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Baseline: Pristup bez TFRecorda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovdje možemo samo utvrditi brzinu učenja, jer nema ulaznog pipeline-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 161us/sample - loss: 0.1699 - accuracy: 0.9473\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0482 - accuracy: 0.9850\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0330 - accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0195 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8cd8ffe88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manualna priprema podataka\n",
    "train_images = X.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "train_labels = y\n",
    "#Učenje\n",
    "model = build_compiled_model()\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Učenje uz TFRecord, bez opcija, bez kompresije i bez optimiziranog pipeline-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiranje dataset-a\n",
    "dataset = base_pipeline(\"test.tfrecord\", dodaj_opcije=False, kompresija=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.1687 - accuracy: 0.9469\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0444 - accuracy: 0.9864\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0305 - accuracy: 0.9905\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0225 - accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0176 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b8e61f5dc8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definiranje modela\n",
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Učenje je 25% brže uz korištenje `TFRecorda` i `tf.data.dataset` za ulaz podataka, u odnosu na naivni uvoz podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.008181425999973726 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1892182999981742,\n",
       " 0.005423999999038642,\n",
       " 0.005437400002847426,\n",
       " 0.005472699998790631,\n",
       " 0.0054841999990458135,\n",
       " 0.0062620000026072375,\n",
       " 0.005466799997520866,\n",
       " 0.005378500001825159]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzine pipeline-a po grupi\n",
    "pipe_1_times = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_1_times[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Učenje uz TFRecord sa opcijama, ali bez kompresije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiranje dataset-a\n",
    "dataset = base_pipeline(\"test.tfrecord\", dodaj_opcije=True, kompresija=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.1703 - accuracy: 0.9468\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0468 - accuracy: 0.9852\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0311 - accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0238 - accuracy: 0.9930\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0184 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9a2539088>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izgleda da odabrane opcije ne pomažu u brzini učenja!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0035410099999717204 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14835259999745176,\n",
       " 0.001577200000610901,\n",
       " 0.0013843999986420386,\n",
       " 0.0015734000007796567,\n",
       " 0.0014102999994065613,\n",
       " 0.0012295000015001278,\n",
       " 0.001069999998435378,\n",
       " 0.0011790999997174367]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzina pipeline-a po grupi\n",
    "pipe_2 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_2[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovo dolje ukazuje da opcije ipak pomažu i to da je pipeline 50% brži!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Učenje uz TFRecord bez opcija, ali s kompresijom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = base_pipeline(\"zip_test.tfrecord\", dodaj_opcije=False, kompresija=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.1722 - accuracy: 0.9458\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0461 - accuracy: 0.9856\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0308 - accuracy: 0.9907\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0237 - accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0179 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9ac1da408>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompresija ne utječe na brzinu učenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.008491692000025069 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1880715000006603,\n",
       " 0.004874900001595961,\n",
       " 0.004905499998130836,\n",
       " 0.006049300001905067,\n",
       " 0.00522859999909997,\n",
       " 0.00633899999957066,\n",
       " 0.009848900001088623,\n",
       " 0.010501400000066496]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzina pipeline-a po grupi\n",
    "pipe_3 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_3[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompresija usporava pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Učenje uz TFRecord s opcijama i sa kompresijom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = base_pipeline(\"zip_test.tfrecord\", dodaj_opcije=True, kompresija=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.1681 - accuracy: 0.9474\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0451 - accuracy: 0.9862\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0308 - accuracy: 0.9905\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0233 - accuracy: 0.9929\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0183 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9aefd6788>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Čini se da kompresija i opcije ne utječu na brzinu učenja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0038078320000204256 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14636270000119112,\n",
       " 0.011732300001312979,\n",
       " 0.00142029999915394,\n",
       " 0.002683499998965999,\n",
       " 0.0016727000001992565,\n",
       " 0.0018038000016531441,\n",
       " 0.0016276999995170627,\n",
       " 0.002558899999712594]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzina pipeline-a po grupi\n",
    "pipe_4 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_4[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovdje je jasno da kompresija nema utjecaj na pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Utjecaj resize slike u pipeline-u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(sample):\n",
    "    '''Radi predprocesuiranja, izlaz je tuple(image, sample)'''\n",
    "    \n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    \n",
    "    #U originalni oblik  - iz 1d u 4d tenzor\n",
    "    image = tf.reshape(image, [-1, 28, 28, 1])\n",
    "   \n",
    "    #Povećavanje slike\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "     #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "     \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za definiranje resize pipeline-a\n",
    "def resize_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija)\n",
    "    dataset = dataset.map(example2sample)\n",
    "    dataset = dataset.map(preprocess_2)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiranje modela sa većim ulazom\n",
    "def build_compiled_model_2():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = resize_pipeline(\"test.tfrecord\", dodaj_opcije=False, kompresija=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected conv2d_18_input to have 4 dimensions, but got array with shape (None, None, 128, 128, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-be629efad31b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_compiled_model_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    682\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    C:\\Users\\Public\\Anaconda3\\envs\\tester\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:573 standardize_input_data\n        'with shape ' + str(data_shape))\n\n    ValueError: Error when checking input: expected conv2d_18_input to have 4 dimensions, but got array with shape (None, None, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "model = build_compiled_model_2()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize je jako skupa operacija u pipeline-u**. Ovaj korak treba napraviti prije nego podatci budu spremljeni u TFRecord formatu!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.01528476600000431 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3369682999982615,\n",
       " 0.011436100001446903,\n",
       " 0.011622699999861652,\n",
       " 0.01291779999883147,\n",
       " 0.011837699999887263,\n",
       " 0.011073199999373173,\n",
       " 0.010455800002091564,\n",
       " 0.010772699999506585]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzina pipeline-a po grupi\n",
    "pipe_5 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_5[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**300% sporije u odnosu na pipeline bez resize unutra !!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. Promjena iz 2 funkcije za predprocesuiranje u jednu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_example2sample(example):\n",
    "    #Obavezno definiramo opis značajki u Exampleu, ovo vraća dict sa image, labelom\n",
    "    feat_desc = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    #Za jedno opažanje\n",
    "    sample = tf.io.parse_example(example, feat_desc)\n",
    "    #Dekodiranje raw byte stringa u sliku koju možemo vizulizirati\n",
    "    sample['image'] = tf.io.decode_raw(sample['image'], tf.uint8)\n",
    "    #Izvuci slike i oznake\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "    #U originalni oblik  - iz 1d u 3d tenzor\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    \n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za definiranje tight pipeline-a\n",
    "def tight_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija)\n",
    "    dataset = dataset.map(integrated_example2sample)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tight_pipeline(\"test.tfrecord\", dodaj_opcije=False, kompresija=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.1688 - accuracy: 0.9479\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0472 - accuracy: 0.9851\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0315 - accuracy: 0.9908\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0241 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0181 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b78477c8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izgleda da su 2 map-a bolja od jednog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.004710695000030682 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13984010000058333,\n",
       " 0.0034278999992238823,\n",
       " 0.0033790000015869737,\n",
       " 0.0037636999986716546,\n",
       " 0.0034894000018539373,\n",
       " 0.003515000000334112,\n",
       " 0.0034278999992238823,\n",
       " 0.0034081000012520235]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brzina pipeline-a po grupi\n",
    "pipe_6 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_6[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaista je sporije od najbrže pipline-a, ajmo pogledati što se događa kada uključimo opcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tight_pipeline(\"test.tfrecord\", dodaj_opcije=True, kompresija=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 937.0 steps\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.1576 - accuracy: 0.9516\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0465 - accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0310 - accuracy: 0.9908\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0185 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b7e407c8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, steps_per_epoch=np.ceil(len(X) // 64), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prvu, izgleda da opcije ne mijenjaju ništa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.003657277999991493 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12762399999701302,\n",
       " 0.0009793000026547816,\n",
       " 0.0010698000005504582,\n",
       " 0.0012150999973528087,\n",
       " 0.0012478999997256324,\n",
       " 0.00093620000188821,\n",
       " 0.001021500000206288,\n",
       " 0.000970599998254329]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_7 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_7[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ali ono što se vidi, je zapravo isto najveća moguća brzina ovog pipeline-a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. Optimizirani pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcija za definiranje tight pipeline-a\n",
    "def opt1_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija, \n",
    "                                      num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "dataset = opt1_pipeline(\"test.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1670 - accuracy: 0.9485\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0483 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0340 - accuracy: 0.9895\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0254 - accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0196 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b24dde08>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.008868260000017471 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7264973000019381,\n",
       " 0.002453699999023229,\n",
       " 0.013757500000792788,\n",
       " 0.00021289999858709052,\n",
       " 0.00016200000027311035,\n",
       " 0.0001512000017100945,\n",
       " 0.00014589999773306772,\n",
       " 0.0013335000003280584]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_8 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_8[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verzija sa opcijama\n",
    "dataset = opt1_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.008844800000006217 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7154526999984228,\n",
       " 0.002690900000743568,\n",
       " 0.0031541999996989034,\n",
       " 0.00304600000163191,\n",
       " 0.0025599000000511296,\n",
       " 0.0027098999998997897,\n",
       " 0.002806399999826681,\n",
       " 0.0019380999983695801]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_9 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_9[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1669 - accuracy: 0.9476\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0462 - accuracy: 0.9862\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0309 - accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0230 - accuracy: 0.9931\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0180 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b8adb148>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt1_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog optimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija, \n",
    "                                      num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt1_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.009324223000003257 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7173960000000079,\n",
       " 0.0025854999985313043,\n",
       " 0.0025744000013219193,\n",
       " 0.0032050999980128836,\n",
       " 0.016780300000391435,\n",
       " 0.0026026000014098827,\n",
       " 0.0035379000000830274,\n",
       " 0.002861000000848435]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_10 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_10[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 9ms/step - loss: 0.1681 - accuracy: 0.9479\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0471 - accuracy: 0.9856\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0321 - accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0237 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 6ms/step - loss: 0.0179 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b90a5e48>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt1_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.TFRecordDataset(tf_rec_data, compression_type=kompresija, \n",
    "                                      num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt1_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.003925657999971009 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2258905999988201,\n",
       " 0.0028138999987277202,\n",
       " 0.0029862000010325573,\n",
       " 0.0025051000011444557,\n",
       " 0.002902599997469224,\n",
       " 0.0028352000008453615,\n",
       " 0.002247299998998642,\n",
       " 0.002609800001664553]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_11 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_11[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9. Optimizirani pipeline II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example2sample(example):\n",
    "    #Obavezno definiramo opis značajki u Exampleu, ovo vraća dict sa image, labelom\n",
    "    feat_desc = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    #Za jedno opažanje\n",
    "    sample = tf.io.parse_example(example, feat_desc)\n",
    "    #Dekodiranje raw byte stringa u sliku koju možemo vizulizirati\n",
    "    sample['image'] = tf.io.decode_raw(sample['image'], tf.uint8)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess(sample):\n",
    "    '''Radi predprocesuiranja, izlaz je tuple(image, sample)'''\n",
    "    \n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "    #U originalni oblik  - iz 1d u 4d tenzor, batch\n",
    "    image = tf.reshape(image, [64, 28, 28, 1])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt2_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog optimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.Dataset.list_files(tf_rec_data)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset,\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #moramo baciti remainder van, jer se inače javlja greška\n",
    "    #u dimenzijama kod reshape funkcije u preproces-u\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(batch_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt2_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.002609623999996984 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20413430000189692,\n",
       " 0.00046949999887146987,\n",
       " 0.0008226999998441897,\n",
       " 0.0004721000004792586,\n",
       " 0.001025199999276083,\n",
       " 0.0004036999998788815,\n",
       " 0.0007413000021188054,\n",
       " 0.0009603999969840515]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_12 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_12[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top speed set-up, kreiranje podataka u odnosu na inicijalni pipeline (0.008 s/batchu) je poboljšano za 88% !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 9ms/step - loss: 0.1710 - accuracy: 0.9470\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0463 - accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0317 - accuracy: 0.9902\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0234 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0186 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc0f0ec788>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moguće je i zadržati zadnji batch, ako definiramo slobodnu dimenziju batch-a. Ovo ću ja morati primijeniti jer ne znam unaprijed koja će biti veličina batcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess_optional_size(sample):\n",
    "    '''Radi predprocesuiranja, izlaz je tuple(image, sample)'''\n",
    "    \n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "    #U originalni oblik  - iz 1d u 4d tenzor, batch (-1), varijabilna veličina batch-a\n",
    "    image = tf.reshape(image, [-1, 28, 28, 1])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt2_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.Dataset.list_files(tf_rec_data)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset,\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #Možemo ali i ne moramo izbacit remainder, jer preprocess funkcija može uzeti u obzir batch varijabilne veličine\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(batch_preprocess_optional_size, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt2_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.002892991000007896 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23144670000328915,\n",
       " 0.0004257000000507105,\n",
       " 0.0006784999968658667,\n",
       " 0.001040600000123959,\n",
       " 0.0008645000016258564,\n",
       " 0.0003515999997034669,\n",
       " 0.0013140000010025688,\n",
       " 0.0007573999973828904]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_13 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_13[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1610 - accuracy: 0.9495\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0461 - accuracy: 0.9859\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0233 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0186 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc2ade5488>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako dodati opciju kompresije u ovaj pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt3_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.Dataset.list_files(tf_rec_data)\n",
    "    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=kompresija),\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #Možemo ali i ne moramo izbacit remainder, jer preprocess funkcija može uzeti u obzir batch varijabilne veličine\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.map(example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(batch_preprocess_optional_size, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt3_pipeline(\"zip_test.tfrecord\", dodaj_opcije=True, kompresija=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.002823346000004676 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20514230000117095,\n",
       " 0.00048690000039641745,\n",
       " 0.0005130999998073094,\n",
       " 0.0023175999995146412,\n",
       " 0.0008621999986644369,\n",
       " 0.0007829000023775734,\n",
       " 0.0008459999990009237,\n",
       " 0.0031009999984235037]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_14 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_14[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 10ms/step - loss: 0.1764 - accuracy: 0.9451\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0449 - accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0315 - accuracy: 0.9905\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0175 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc47761448>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samo provjera funkcije bez kompresije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt3_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0009626600000046892 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.031069000000570668,\n",
       " 0.0004226000019116327,\n",
       " 0.0003259999975853134,\n",
       " 0.0010013000028266106,\n",
       " 0.0005318999974406324,\n",
       " 0.0007809000017005019,\n",
       " 0.0004307999988668598,\n",
       " 0.0009099000017158687]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_15 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_15[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompresije usporava pipeline za 50% !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 9ms/step - loss: 0.1686 - accuracy: 0.9478\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0486 - accuracy: 0.9851\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0333 - accuracy: 0.9898\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0199 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc47aecbc8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ali to se ne odražava na vremenu učenja, vjerojatno zbog brzine GPU-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt3_pipeline(\"test.tfrecord\", dodaj_opcije=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0008493359999920358 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03104459999667597,\n",
       " 0.0003826000029221177,\n",
       " 0.00046189999920898117,\n",
       " 0.0007879000004322734,\n",
       " 0.0006795000008423813,\n",
       " 0.0006749999993189704,\n",
       " 0.0006162999998196028,\n",
       " 0.00031939999826136045]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_16 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_16[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovdje se pokazalo čak da opcije nemaju nikakav efekt!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_compiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 8s 9ms/step - loss: 0.1689 - accuracy: 0.9480698 - accuracy\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0475 - accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0326 - accuracy: 0.9895\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0250 - accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 6s 7ms/step - loss: 0.0190 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9b8a8bf48>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiranje brzine pipeline-a ako postoji samo jedna funkcija za map, tj. ako se parser i preprocess funkcije objedine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_example2sample(example):\n",
    "    #Obavezno definiramo opis značajki u Exampleu, ovo vraća dict sa image, labelom\n",
    "    feat_desc = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    #Za jedno opažanje\n",
    "    sample = tf.io.parse_example(example, feat_desc)\n",
    "    #Dekodiranje raw byte stringa u sliku koju možemo vizulizirati\n",
    "    sample['image'] = tf.io.decode_raw(sample['image'], tf.uint8)\n",
    "    #Izvuci slike i oznake\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #U float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #normalizacija\n",
    "    image = image / 255.\n",
    "    #U originalni oblik  - iz 1d u 4d tenzor\n",
    "    image = tf.reshape(image, [-1, 28, 28, 1])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt4_pipeline(tf_rec_data, dodaj_opcije=False, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.Dataset.list_files(tf_rec_data)\n",
    "    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=kompresija),\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #Možemo ali i ne moramo izbacit remainder, jer preprocess funkcija može uzeti u obzir batch varijabilne veličine\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.map(integrated_example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if dodaj_opcije:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        \n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt4_pipeline(\"test.tfrecord\", dodaj_opcije=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0007445459999871673 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.026995399999577785,\n",
       " 0.00032310000096913427,\n",
       " 0.0003622999975050334,\n",
       " 0.0006329000025289133,\n",
       " 0.00075970000034431,\n",
       " 0.0004692999973485712,\n",
       " 0.00036779999936698005,\n",
       " 0.0003829000015684869]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_17 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_17[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 9ms/step - loss: 0.1645 - accuracy: 0.9497\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.0454 - accuracy: 0.9861\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.0312 - accuracy: 0.9902\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.0237 - accuracy: 0.9930\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.0183 - accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc4885be88>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaključak je da parser i preprocess funkcija mogu biti spojene bez efekta na učinkovitost pipeline-a, čak i bez opcija!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idemo vidjeti što se događa ako u potpunosti izbacimo opcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt5_pipeline(tf_rec_data, kompresija=None):\n",
    "    '''Funkcija za generiranje ulaznog neoptimiziranog pipeline-a,\n",
    "    iz tfrecorda, sa ili bez opcija'''\n",
    "    dataset = tf.data.Dataset.list_files(tf_rec_data)\n",
    "    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=kompresija),\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #Možemo ali i ne moramo izbacit remainder, jer preprocess funkcija može uzeti u obzir batch varijabilne veličine\n",
    "    dataset = dataset.batch(64, drop_remainder=True)\n",
    "    dataset = dataset.map(integrated_example2sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = opt5_pipeline(\"test.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Početak mjerenja\n",
      "Kraj mjerenja\n",
      "Prosječno vrijeme po batchu: 0.0008257979998597875 sekundi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028442699986044317,\n",
       " 0.0005489999894052744,\n",
       " 0.0004710000357590616,\n",
       " 0.00092299998505041,\n",
       " 0.00042269995901733637,\n",
       " 0.0003964000497944653,\n",
       " 0.0005043999990448356,\n",
       " 0.0004267999902367592]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_18 = pipeline_timer(dataset, num_iterations=100)\n",
    "pipe_18[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 9s 10ms/step - loss: 0.1745 - accuracy: 0.9457\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0475 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0330 - accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 7s 7ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 7s 8ms/step - loss: 0.0193 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cc49edde88>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_compiled_model()\n",
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcije ne utječu na brzinu učenja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provjera da li pipeline vraća slike koje očekujemo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pipeline kojeg ću koristiti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definirana funkcija za izgradnju optimiziranog pipeline-a. Bitna je definirati vektoriziranu funkciju (funkciju koja prima kao ulaz grupu uzoraka) za parsiranje tfrecord-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(file_pattern, batch_size, parser_fun, \n",
    "                   add_options=False, compression=None):\n",
    "    \n",
    "    '''Funkcija za generiranje optimiziranog pipeline-a iz direktorija koji sadrži tfrecord-e\n",
    "    \n",
    "    Argumenti\n",
    "    ---------\n",
    "    file_pattern: str\n",
    "    glob obrazac za matchiranje/prepoznavanje datoteka, npr. \"*.tfrecord\", moguće je zadati i \n",
    "    punu putanju do direktorija\n",
    "    \n",
    "    batch_size: int\n",
    "    Veličina mini grupe za učenje modela\n",
    "    \n",
    "    parser_fun: fun\n",
    "    Vektorizirana funkcija za parsiranje tfrecord datoteke u format pogodane za daljnju obradu\n",
    "    primjenom modela\n",
    "    \n",
    "    dodaj_opcije: bool\n",
    "    Dodavanje statičkih optimizacija pipeline-a, zadana vrijednost je False\n",
    "    \n",
    "    kompresija: str\n",
    "    Da li su podatci komprimirani, npr. u GZIP formatu, zadana vrijednost je None\n",
    "    \n",
    "    Povratna vrijednost\n",
    "    -------------------\n",
    "    dataset: tf.data.Dataset\n",
    "    Instanca tf.data.Dataset klase pogodna za obradu modelom\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dataset = tf.data.Dataset.list_files(file_pattern)\n",
    "    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=compression),\n",
    "                                 cycle_length=tf.data.experimental.AUTOTUNE,\n",
    "                                 num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    #U slučaju da je zadnji batch manje veličine u odnosu na puni batch, izbaci ga\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.map(parser_fun, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    #Statičke optmiziacije\n",
    "    if add_options:\n",
    "        options = tf.data.Options()\n",
    "        options.experimental_optimization.map_and_batch_fusion = True\n",
    "        options.experimental_optimization.map_fusion = True\n",
    "        options.experimental_optimization.map_parallelization = True\n",
    "        dataset = dataset.with_options(options)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primjer parser funkcije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example2sample(example):\n",
    "    #Obavezno definiramo opis značajki pohranjenih u Example-u, ovo vraća dict sa ključevima: image, label\n",
    "    feat_desc = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    #Za parsiranje više Example-ova\n",
    "    sample = tf.io.parse_example(example, feat_desc)\n",
    "    #Dekodiranje raw byte stringa u uint8, ovo sada možemo i vizualizirati\n",
    "    sample['image'] = tf.io.decode_raw(sample['image'], tf.uint8)\n",
    "    #Izvuci slike i oznake\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    #Konverzija u float, inače nije moguća primjena gradijentne metode\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    #Normalizacija u raspon [0, 1]\n",
    "    image = image / 255.\n",
    "    #Preoblikovanje u grupe slika u originalne dimenizije iz 1d tenzora u 4d tenzor,\n",
    "    #uz proizvoljan broj slika u mini grupi (vektorizacija) \n",
    "    image = tf.reshape(image, [-1, 28, 28, 1])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
